{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/vae.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Incompatibility detected between CUDA and LLVM 8.0+; disabling debug info emission for CUDA kernels\n",
      "└ @ CUDAnative /home/cavani/Workspace/julia-abc/software/julia-env/packages/CUDAnative/hfulr/src/CUDAnative.jl:114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "using CuArrays\n",
    "using Images\n",
    "using Statistics\n",
    "using Plots\n",
    "using Plots.PlotMeasures\n",
    "import Random: seed!\n",
    "\n",
    "CuArrays.allowscalar(false)\n",
    "\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Downloading MNIST dataset\n",
      "└ @ Flux.Data.MNIST /home/cavani/Workspace/julia-abc/software/julia-env/packages/Flux/NpkMm/src/data/mnist.jl:24\n",
      "┌ Info: Downloading MNIST dataset\n",
      "└ @ Flux.Data.MNIST /home/cavani/Workspace/julia-abc/software/julia-env/packages/Flux/NpkMm/src/data/mnist.jl:24\n",
      "┌ Info: Downloading MNIST dataset\n",
      "└ @ Flux.Data.MNIST /home/cavani/Workspace/julia-abc/software/julia-env/packages/Flux/NpkMm/src/data/mnist.jl:24\n",
      "┌ Info: Downloading MNIST dataset\n",
      "└ @ Flux.Data.MNIST /home/cavani/Workspace/julia-abc/software/julia-env/packages/Flux/NpkMm/src/data/mnist.jl:24\n",
      "┌ Info: Building the CUDAnative run-time library for your sm_35 device, this might take a while...\n",
      "└ @ CUDAnative /home/cavani/Workspace/julia-abc/software/julia-env/packages/CUDAnative/hfulr/src/compiler/rtlib.jl:188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-element Array{CuArray{Float32,2,Nothing},1}:\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " ⋮\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data, binarise it, and partition into mini-batches of M.\n",
    "\n",
    "import Flux.Data.MNIST\n",
    "\n",
    "function load_mnist_binary(split_name; use_gpu=true)\n",
    "    X = float.(hcat(vec.(MNIST.images(split_name))...)) .> 0.5\n",
    "    if use_gpu\n",
    "        X = gpu(X)\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function make_batches(X, batch_size)\n",
    "    num_examples = size(X, 2)\n",
    "    data = [X[:, i] for i in Iterators.partition(1:num_examples, batch_size)]\n",
    "    return data\n",
    "end\n",
    "\n",
    "X = load_mnist_binary(:train)\n",
    "X_eval = load_mnist_binary(:test)\n",
    "M = 100\n",
    "train_data = make_batches(X, M)\n",
    "eval_data = make_batches(X_eval, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×10 CuArray{Float32,2,Nothing}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sample_X(X, sample_size)\n",
    "    indices = rand(1:size(X, 2), sample_size)\n",
    "    X̃ = X[:, indices]\n",
    "    return X̃\n",
    "end\n",
    "\n",
    "X̃ = sample_X(X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Define Model #################################\n",
    "\n",
    "import Flux: functor\n",
    "\n",
    "e = Float32(ℯ)\n",
    "\n",
    "# Components of recognition model / \"encoder\" MLP.\n",
    "struct Encoder\n",
    "    A\n",
    "    μ\n",
    "    logσ\n",
    "end\n",
    "\n",
    "functor(g::Encoder) = (g.A, g.μ, g.logσ), y -> Encoder(y...)\n",
    "\n",
    "function (g::Encoder)(X)\n",
    "    A, μ, logσ = g.A, g.μ, g.logσ\n",
    "    h = A(X)\n",
    "    return μ(h), logσ(h)\n",
    "end\n",
    "\n",
    "function make_encoder(example_size, hidden_size, encoded_size; use_gpu=true)\n",
    "    A = Dense(example_size, hidden_size, tanh)\n",
    "    μ = Dense(hidden_size, encoded_size)\n",
    "    logσ = Dense(hidden_size, encoded_size)\n",
    "    \n",
    "    if use_gpu\n",
    "        A = gpu(A)\n",
    "        μ = gpu(μ)\n",
    "        logσ = gpu(logσ)\n",
    "    end\n",
    "    \n",
    "    encoder = Encoder(A, μ, logσ)\n",
    "    \n",
    "    return encoder\n",
    "end\n",
    "\n",
    "# Generative model / \"decoder\" MLP.\n",
    "function make_decoder(example_size, hidden_size, encoded_size; use_gpu=true)\n",
    "    decoder = Chain(\n",
    "        Dense(encoded_size, hidden_size, tanh),\n",
    "        Dense(hidden_size, example_size, σ)\n",
    "    )\n",
    "    \n",
    "    if use_gpu\n",
    "        decoder = gpu(decoder)\n",
    "    end\n",
    "    \n",
    "    return decoder\n",
    "end\n",
    "\n",
    "function z(μ, logσ; use_gpu=true)\n",
    "    noise = randn(Float32, size(logσ)...)\n",
    "    if use_gpu\n",
    "        noise = gpu(noise)\n",
    "    end\n",
    "    return μ + (e .^ logσ) .* noise\n",
    "end\n",
    "\n",
    "# Image size, Latent dimensionality, # hidden units.\n",
    "Dx = 28 ^ 2\n",
    "Dh = 500\n",
    "Dz = 5\n",
    "\n",
    "g = make_encoder(Dx, Dh, Dz)\n",
    "f = make_decoder(Dx, Dh, Dz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : (500, 784)\n",
      "2 : (500,)\n",
      "3 : (5, 500)\n",
      "4 : (5,)\n",
      "5 : (5, 500)\n",
      "6 : (5,)\n"
     ]
    }
   ],
   "source": [
    "θg = params(g)\n",
    "\n",
    "for (i, θg′) in enumerate(θg)\n",
    "    println(i, \" : \", size(θg′))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : (500, 5)\n",
      "2 : (500,)\n",
      "3 : (784, 500)\n",
      "4 : (784,)\n"
     ]
    }
   ],
   "source": [
    "θf = params(f)\n",
    "\n",
    "for (i, θf′) in enumerate(θf)\n",
    "    println(i, \" : \", size(θf′))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x₁    : (784, 100)\n",
      "μ₁    : (5, 100)\n",
      "logσ₁ : (5, 100)\n"
     ]
    }
   ],
   "source": [
    "x₁ = train_data[1]\n",
    "μ₁, logσ₁ = g(x₁)\n",
    "\n",
    "println(\"x₁    : \", size(x₁))\n",
    "println(\"μ₁    : \", size(μ₁))\n",
    "println(\"logσ₁ : \", size(logσ₁))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z₁    : (5, 100)\n"
     ]
    }
   ],
   "source": [
    "z₁ = z(μ₁, logσ₁)\n",
    "\n",
    "println(\"z₁    : \", size(z₁))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x₁′   : (784, 100)\n"
     ]
    }
   ],
   "source": [
    "x₁′ = f(z₁)\n",
    "\n",
    "println(\"x₁′   : \", size(x₁′))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2517066\n"
     ]
    }
   ],
   "source": [
    "mse₁ = Flux.mse(x₁′, x₁)\n",
    "\n",
    "println(mse₁)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548.37317f0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################### Define ways of doing things with the model. #######################\n",
    "\n",
    "import Flux: binarycrossentropy\n",
    "\n",
    "# log p(x|z) - conditional probability of data given latents.\n",
    "log_p_x_z(x, z) = -sum(binarycrossentropy.(f(z), x))\n",
    "\n",
    "# KL-divergence between approximation posterior and N(0, 1) prior.\n",
    "kl_q_p(μ, logσ) = 0.5f0 * sum(e .^ (2f0 .* logσ) + μ .^ 2 .- 1f0 .- (2 .* logσ))\n",
    "\n",
    "# Monte Carlo estimator of mean ELBO using M samples.\n",
    "function L̄(X)\n",
    "    μ′, logσ′ = g(X)\n",
    "    z′ = z(μ′, logσ′)\n",
    "    (log_p_x_z(X, z′) - kl_q_p(μ′, logσ′)) * 1 // M\n",
    "end\n",
    "\n",
    "seed!(42)\n",
    "g = make_encoder(Dx, Dh, Dz)\n",
    "f = make_decoder(Dx, Dh, Dz)\n",
    "X̃ = sample_X(X, M)\n",
    "\n",
    "-L̄(X̃) # 548.37317f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " 60.234769 seconds (73.96 M allocations: 3.582 GiB, 2.30% gc time)\n",
      "Train Loss : 161.7681\n",
      "Eval Loss  : 160.8458\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 2\n",
      " 10.363442 seconds (6.01 M allocations: 234.790 MiB, 1.34% gc time)\n",
      "Train Loss : 150.0963\n",
      "Eval Loss  : 149.1542\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 3\n",
      " 10.309282 seconds (6.01 M allocations: 234.119 MiB, 1.28% gc time)\n",
      "Train Loss : 143.7455\n",
      "Eval Loss  : 143.0081\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 4\n",
      " 10.308355 seconds (6.01 M allocations: 234.773 MiB, 1.30% gc time)\n",
      "Train Loss : 140.247\n",
      "Eval Loss  : 139.6708\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 5\n",
      " 10.306472 seconds (6.01 M allocations: 234.785 MiB, 1.38% gc time)\n",
      "Train Loss : 137.2818\n",
      "Eval Loss  : 136.8394\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 6\n",
      " 10.383645 seconds (6.01 M allocations: 234.052 MiB, 1.41% gc time)\n",
      "Train Loss : 134.4889\n",
      "Eval Loss  : 134.0652\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 7\n",
      " 10.389345 seconds (6.01 M allocations: 234.753 MiB, 1.40% gc time)\n",
      "Train Loss : 133.9711\n",
      "Eval Loss  : 133.5398\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 8\n",
      " 10.403633 seconds (6.01 M allocations: 234.801 MiB, 1.40% gc time)\n",
      "Train Loss : 132.1757\n",
      "Eval Loss  : 131.8655\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 9\n",
      " 10.602101 seconds (6.01 M allocations: 234.128 MiB, 1.34% gc time)\n",
      "Train Loss : 131.6492\n",
      "Eval Loss  : 131.3004\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 10\n",
      " 10.357871 seconds (6.01 M allocations: 234.747 MiB, 1.31% gc time)\n",
      "Train Loss : 130.8054\n",
      "Eval Loss  : 130.531\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 11\n",
      " 10.324740 seconds (6.01 M allocations: 234.715 MiB, 1.30% gc time)\n",
      "Train Loss : 130.4908\n",
      "Eval Loss  : 130.2372\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 12\n",
      " 10.313148 seconds (6.01 M allocations: 234.138 MiB, 1.39% gc time)\n",
      "Train Loss : 129.9276\n",
      "Eval Loss  : 129.6406\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 13\n",
      " 10.312487 seconds (6.01 M allocations: 234.762 MiB, 1.40% gc time)\n",
      "Train Loss : 128.9675\n",
      "Eval Loss  : 128.7473\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 14\n",
      " 10.308933 seconds (6.01 M allocations: 234.782 MiB, 1.40% gc time)\n",
      "Train Loss : 128.7732\n",
      "Eval Loss  : 128.5773\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 15\n",
      " 10.313674 seconds (6.01 M allocations: 234.113 MiB, 1.32% gc time)\n",
      "Train Loss : 128.9017\n",
      "Eval Loss  : 128.6886\n",
      "\n",
      "Epoch 16\n",
      " 10.305677 seconds (6.01 M allocations: 234.706 MiB, 1.26% gc time)\n",
      "Train Loss : 127.8905\n",
      "Eval Loss  : 127.7061\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 17\n",
      " 10.316872 seconds (6.01 M allocations: 234.790 MiB, 1.34% gc time)\n",
      "Train Loss : 127.9827\n",
      "Eval Loss  : 127.7549\n",
      "\n",
      "Epoch 18\n",
      " 10.299870 seconds (6.01 M allocations: 234.119 MiB, 1.28% gc time)\n",
      "Train Loss : 127.4815\n",
      "Eval Loss  : 127.2491\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 19\n",
      " 10.390943 seconds (6.01 M allocations: 234.753 MiB, 1.42% gc time)\n",
      "Train Loss : 127.8772\n",
      "Eval Loss  : 127.7965\n",
      "\n",
      "Epoch 20\n",
      " 10.374145 seconds (6.01 M allocations: 234.795 MiB, 1.41% gc time)\n",
      "Train Loss : 127.2508\n",
      "Eval Loss  : 127.0482\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 21\n",
      " 10.292443 seconds (6.01 M allocations: 234.060 MiB, 1.29% gc time)\n",
      "Train Loss : 127.0899\n",
      "Eval Loss  : 126.939\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 22\n",
      " 10.334444 seconds (6.01 M allocations: 234.753 MiB, 1.30% gc time)\n",
      "Train Loss : 127.2273\n",
      "Eval Loss  : 127.1073\n",
      "\n",
      "Epoch 23\n",
      " 10.353189 seconds (6.01 M allocations: 234.782 MiB, 1.30% gc time)\n",
      "Train Loss : 127.1311\n",
      "Eval Loss  : 126.9624\n",
      "\n",
      "Epoch 24\n",
      " 10.350543 seconds (6.01 M allocations: 234.138 MiB, 1.28% gc time)\n",
      "Train Loss : 127.0894\n",
      "Eval Loss  : 127.0179\n",
      "\n",
      "Epoch 25\n",
      " 10.367912 seconds (6.01 M allocations: 234.756 MiB, 1.28% gc time)\n",
      "Train Loss : 126.784\n",
      "Eval Loss  : 126.7333\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 26\n",
      " 10.384078 seconds (6.01 M allocations: 234.714 MiB, 1.32% gc time)\n",
      "Train Loss : 127.001\n",
      "Eval Loss  : 126.9001\n",
      "\n",
      "Epoch 27\n",
      " 10.349443 seconds (6.01 M allocations: 234.119 MiB, 1.28% gc time)\n",
      "Train Loss : 126.5925\n",
      "Eval Loss  : 126.4941\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 28\n",
      " 10.292468 seconds (6.01 M allocations: 234.773 MiB, 1.29% gc time)\n",
      "Train Loss : 126.4915\n",
      "Eval Loss  : 126.4818\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 29\n",
      " 10.310750 seconds (6.01 M allocations: 234.790 MiB, 1.31% gc time)\n",
      "Train Loss : 126.6678\n",
      "Eval Loss  : 126.6421\n",
      "\n",
      "Epoch 30\n",
      " 10.523276 seconds (6.01 M allocations: 234.113 MiB, 1.41% gc time)\n",
      "Train Loss : 126.5741\n",
      "Eval Loss  : 126.539\n",
      "\n",
      "Epoch 31\n",
      " 10.407873 seconds (6.01 M allocations: 234.686 MiB, 1.36% gc time)\n",
      "Train Loss : 126.4307\n",
      "Eval Loss  : 126.4238\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 32\n",
      " 10.422274 seconds (6.01 M allocations: 234.801 MiB, 1.43% gc time)\n",
      "Train Loss : 126.8807\n",
      "Eval Loss  : 126.9222\n",
      "\n",
      "Epoch 33\n",
      " 10.315567 seconds (6.01 M allocations: 234.128 MiB, 1.39% gc time)\n",
      "Train Loss : 127.1688\n",
      "Eval Loss  : 127.1744\n",
      "\n",
      "Epoch 34\n",
      " 10.302794 seconds (6.01 M allocations: 234.753 MiB, 1.40% gc time)\n",
      "Train Loss : 126.8609\n",
      "Eval Loss  : 126.8885\n",
      "\n",
      "Epoch 35\n",
      " 10.321457 seconds (6.01 M allocations: 234.776 MiB, 1.42% gc time)\n",
      "Train Loss : 126.3455\n",
      "Eval Loss  : 126.327\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 36\n",
      " 10.379372 seconds (6.01 M allocations: 234.071 MiB, 1.34% gc time)\n",
      "Train Loss : 126.7181\n",
      "Eval Loss  : 126.7421\n",
      "\n",
      "Epoch 37\n",
      " 10.354593 seconds (6.01 M allocations: 234.762 MiB, 1.28% gc time)\n",
      "Train Loss : 126.3254\n",
      "Eval Loss  : 126.402\n",
      "\n",
      "Epoch 38\n",
      " 10.313500 seconds (6.01 M allocations: 234.782 MiB, 1.28% gc time)\n",
      "Train Loss : 126.2497\n",
      "Eval Loss  : 126.2828\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 39\n",
      " 10.320912 seconds (6.01 M allocations: 234.119 MiB, 1.32% gc time)\n",
      "Train Loss : 126.1296\n",
      "Eval Loss  : 126.2067\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 40\n",
      " 10.307284 seconds (6.01 M allocations: 234.767 MiB, 1.32% gc time)\n",
      "Train Loss : 126.1608\n",
      "Eval Loss  : 126.2622\n",
      "\n",
      "Epoch 41\n",
      " 10.282712 seconds (6.01 M allocations: 234.723 MiB, 1.30% gc time)\n",
      "Train Loss : 126.3816\n",
      "Eval Loss  : 126.464\n",
      "\n",
      "Epoch 42\n",
      " 10.284429 seconds (6.01 M allocations: 234.119 MiB, 1.32% gc time)\n",
      "Train Loss : 126.193\n",
      "Eval Loss  : 126.2995\n",
      "\n",
      "Epoch 43\n",
      " 10.303297 seconds (6.01 M allocations: 234.753 MiB, 1.31% gc time)\n",
      "Train Loss : 125.9657\n",
      "Eval Loss  : 126.034\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 44\n",
      " 10.317086 seconds (6.01 M allocations: 234.801 MiB, 1.34% gc time)\n",
      "Train Loss : 127.0851\n",
      "Eval Loss  : 127.1894\n",
      "\n",
      "Epoch 45\n",
      " 10.291228 seconds (6.01 M allocations: 234.122 MiB, 1.32% gc time)\n",
      "Train Loss : 126.4248\n",
      "Eval Loss  : 126.5674\n",
      "\n",
      "Epoch 46\n",
      " 10.287534 seconds (6.01 M allocations: 234.686 MiB, 1.32% gc time)\n",
      "Train Loss : 126.466\n",
      "Eval Loss  : 126.6416\n",
      "\n",
      "Epoch 47\n",
      " 10.294595 seconds (6.01 M allocations: 234.782 MiB, 1.31% gc time)\n",
      "Train Loss : 126.844\n",
      "Eval Loss  : 126.9967\n",
      "\n",
      "Epoch 48\n",
      " 10.296161 seconds (6.01 M allocations: 234.138 MiB, 1.35% gc time)\n",
      "Train Loss : 126.3715\n",
      "Eval Loss  : 126.5142\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "\n",
      "Epoch 49\n",
      " 10.318064 seconds (6.01 M allocations: 234.762 MiB, 1.47% gc time)\n",
      "Train Loss : 123.1014\n",
      "Eval Loss  : 123.4414\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 50\n",
      " 10.396160 seconds (6.01 M allocations: 234.776 MiB, 1.48% gc time)\n",
      "Train Loss : 123.0656\n",
      "Eval Loss  : 123.4027\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 51\n",
      " 10.399446 seconds (6.01 M allocations: 234.052 MiB, 1.47% gc time)\n",
      "Train Loss : 123.0099\n",
      "Eval Loss  : 123.3786\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 52\n",
      " 10.395816 seconds (6.01 M allocations: 234.773 MiB, 1.44% gc time)\n",
      "Train Loss : 123.0071\n",
      "Eval Loss  : 123.3839\n",
      "\n",
      "Epoch 53\n",
      " 10.371694 seconds (6.01 M allocations: 234.790 MiB, 1.42% gc time)\n",
      "Train Loss : 122.9443\n",
      "Eval Loss  : 123.3191\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 54\n",
      " 10.302035 seconds (6.01 M allocations: 234.119 MiB, 1.34% gc time)\n",
      "Train Loss : 122.9137\n",
      "Eval Loss  : 123.2988\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 55\n",
      " 10.382825 seconds (6.01 M allocations: 234.748 MiB, 1.36% gc time)\n",
      "Train Loss : 122.9086\n",
      "Eval Loss  : 123.2846\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 56\n",
      " 10.330292 seconds (6.01 M allocations: 234.734 MiB, 1.33% gc time)\n",
      "Train Loss : 122.8731\n",
      "Eval Loss  : 123.294\n",
      "\n",
      "Epoch 57\n",
      " 10.312749 seconds (6.01 M allocations: 234.128 MiB, 1.31% gc time)\n",
      "Train Loss : 122.8802\n",
      "Eval Loss  : 123.2395\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 58\n",
      " 10.305588 seconds (6.01 M allocations: 234.753 MiB, 1.34% gc time)\n",
      "Train Loss : 122.7992\n",
      "Eval Loss  : 123.2357\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 59\n",
      " 10.338171 seconds (6.01 M allocations: 234.782 MiB, 1.33% gc time)\n",
      "Train Loss : 122.7998\n",
      "Eval Loss  : 123.1471\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 60\n",
      " 10.381818 seconds (6.01 M allocations: 234.133 MiB, 1.39% gc time)\n",
      "Train Loss : 122.7769\n",
      "Eval Loss  : 123.1404\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 61\n",
      " 10.387370 seconds (6.01 M allocations: 234.695 MiB, 1.47% gc time)\n",
      "Train Loss : 122.7955\n",
      "Eval Loss  : 123.1783\n",
      "\n",
      "Epoch 62\n",
      " 10.298347 seconds (6.01 M allocations: 234.782 MiB, 1.31% gc time)\n",
      "Train Loss : 122.7276\n",
      "Eval Loss  : 123.1142\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 63\n",
      " 10.319707 seconds (6.01 M allocations: 234.119 MiB, 1.38% gc time)\n",
      "Train Loss : 122.7109\n",
      "Eval Loss  : 123.1302\n",
      "\n",
      "Epoch 64\n",
      " 10.312515 seconds (6.01 M allocations: 234.773 MiB, 1.32% gc time)\n",
      "Train Loss : 122.7139\n",
      "Eval Loss  : 123.1408\n",
      "\n",
      "Epoch 65\n",
      " 10.294190 seconds (6.01 M allocations: 234.785 MiB, 1.32% gc time)\n",
      "Train Loss : 122.7037\n",
      "Eval Loss  : 123.1111\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 66\n",
      " 10.306858 seconds (6.01 M allocations: 234.052 MiB, 1.36% gc time)\n",
      "Train Loss : 122.6748\n",
      "Eval Loss  : 123.0582\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 67\n",
      " 10.397084 seconds (6.01 M allocations: 234.753 MiB, 1.49% gc time)\n",
      "Train Loss : 122.701\n",
      "Eval Loss  : 123.1211\n",
      "\n",
      "Epoch 68\n",
      " 10.398576 seconds (6.01 M allocations: 234.801 MiB, 1.44% gc time)\n",
      "Train Loss : 122.6486\n",
      "Eval Loss  : 123.0764\n",
      "\n",
      "Epoch 69\n",
      " 10.392516 seconds (6.01 M allocations: 234.128 MiB, 1.45% gc time)\n",
      "Train Loss : 122.6294\n",
      "Eval Loss  : 123.0529\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 70\n",
      " 10.344671 seconds (6.01 M allocations: 234.747 MiB, 1.37% gc time)\n",
      "Train Loss : 122.6657\n",
      "Eval Loss  : 123.1408\n",
      "\n",
      "Epoch 71\n",
      " 10.363733 seconds (6.01 M allocations: 234.715 MiB, 1.38% gc time)\n",
      "Train Loss : 122.6154\n",
      "Eval Loss  : 123.056\n",
      "\n",
      "Epoch 72\n",
      " 10.358495 seconds (6.01 M allocations: 234.138 MiB, 1.33% gc time)\n",
      "Train Loss : 122.607\n",
      "Eval Loss  : 123.0358\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 73\n",
      " 10.330296 seconds (6.01 M allocations: 234.762 MiB, 1.47% gc time)\n",
      "Train Loss : 122.5513\n",
      "Eval Loss  : 123.039\n",
      "\n",
      "Epoch 74\n",
      " 10.310323 seconds (6.01 M allocations: 234.782 MiB, 1.45% gc time)\n",
      "Train Loss : 122.5809\n",
      "Eval Loss  : 122.9846\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 75\n",
      " 10.294369 seconds (6.01 M allocations: 234.113 MiB, 1.35% gc time)\n",
      "Train Loss : 122.5755\n",
      "Eval Loss  : 123.0493\n",
      "\n",
      "Epoch 76\n",
      " 10.303182 seconds (6.01 M allocations: 234.706 MiB, 1.35% gc time)\n",
      "Train Loss : 122.5586\n",
      "Eval Loss  : 122.9715\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 77\n",
      " 10.303072 seconds (6.01 M allocations: 234.790 MiB, 1.35% gc time)\n",
      "Train Loss : 122.55\n",
      "Eval Loss  : 123.0058\n",
      "\n",
      "Epoch 78\n",
      " 10.305062 seconds (6.01 M allocations: 234.119 MiB, 1.38% gc time)\n",
      "Train Loss : 122.5452\n",
      "Eval Loss  : 122.9871\n",
      "\n",
      "Epoch 79\n",
      " 10.303642 seconds (6.01 M allocations: 234.753 MiB, 1.37% gc time)\n",
      "Train Loss : 122.5318\n",
      "Eval Loss  : 123.0289\n",
      "\n",
      "Epoch 80\n",
      " 10.283622 seconds (6.01 M allocations: 234.795 MiB, 1.35% gc time)\n",
      "Train Loss : 122.5562\n",
      "Eval Loss  : 123.0393\n",
      "\n",
      "Epoch 81\n",
      " 10.287071 seconds (6.01 M allocations: 234.060 MiB, 1.34% gc time)\n",
      "Train Loss : 122.5035\n",
      "Eval Loss  : 122.9352\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 82\n",
      " 10.305893 seconds (6.01 M allocations: 234.753 MiB, 1.37% gc time)\n",
      "Train Loss : 122.5215\n",
      "Eval Loss  : 122.9513\n",
      "\n",
      "Epoch 83\n",
      " 10.286053 seconds (6.01 M allocations: 234.782 MiB, 1.36% gc time)\n",
      "Train Loss : 122.5302\n",
      "Eval Loss  : 123.0218\n",
      "\n",
      "Epoch 84\n",
      " 10.293345 seconds (6.01 M allocations: 234.138 MiB, 1.37% gc time)\n",
      "Train Loss : 122.4836\n",
      "Eval Loss  : 122.9095\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 85\n",
      " 10.324701 seconds (6.01 M allocations: 234.756 MiB, 1.38% gc time)\n",
      "Train Loss : 122.4779\n",
      "Eval Loss  : 122.9008\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 86\n",
      " 10.322754 seconds (6.01 M allocations: 234.714 MiB, 1.51% gc time)\n",
      "Train Loss : 122.5262\n",
      "Eval Loss  : 122.9862\n",
      "\n",
      "Epoch 87\n",
      " 10.321887 seconds (6.01 M allocations: 234.119 MiB, 1.48% gc time)\n",
      "Train Loss : 122.4898\n",
      "Eval Loss  : 122.92\n",
      "\n",
      "Epoch 88\n",
      " 10.310640 seconds (6.01 M allocations: 234.773 MiB, 1.40% gc time)\n",
      "Train Loss : 122.4776\n",
      "Eval Loss  : 122.9496\n",
      "\n",
      "Epoch 89\n",
      " 10.306693 seconds (6.01 M allocations: 234.790 MiB, 1.36% gc time)\n",
      "Train Loss : 122.4702\n",
      "Eval Loss  : 122.9281\n",
      "\n",
      "Epoch 90\n",
      " 10.295971 seconds (6.01 M allocations: 234.113 MiB, 1.35% gc time)\n",
      "Train Loss : 122.459\n",
      "Eval Loss  : 122.924\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "\n",
      "Epoch 91\n",
      " 10.302352 seconds (6.01 M allocations: 234.686 MiB, 1.36% gc time)\n",
      "Train Loss : 122.2243\n",
      "Eval Loss  : 122.6083\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 92\n",
      " 10.353893 seconds (6.01 M allocations: 234.801 MiB, 1.39% gc time)\n",
      "Train Loss : 122.189\n",
      "Eval Loss  : 122.6112\n",
      "\n",
      "Epoch 93\n",
      " 10.351032 seconds (6.01 M allocations: 234.128 MiB, 1.39% gc time)\n",
      "Train Loss : 122.1555\n",
      "Eval Loss  : 122.5848\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 94\n",
      " 10.304876 seconds (6.01 M allocations: 234.753 MiB, 1.40% gc time)\n",
      "Train Loss : 122.178\n",
      "Eval Loss  : 122.622\n",
      "\n",
      "Epoch 95\n",
      " 10.302734 seconds (6.01 M allocations: 234.776 MiB, 1.34% gc time)\n",
      "Train Loss : 122.1888\n",
      "Eval Loss  : 122.6092\n",
      "\n",
      "Epoch 96\n",
      " 10.344136 seconds (6.01 M allocations: 234.071 MiB, 1.34% gc time)\n",
      "Train Loss : 122.1668\n",
      "Eval Loss  : 122.5799\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 97\n",
      " 10.309598 seconds (6.01 M allocations: 234.762 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1832\n",
      "Eval Loss  : 122.5618\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 98\n",
      " 10.319865 seconds (6.01 M allocations: 234.782 MiB, 1.53% gc time)\n",
      "Train Loss : 122.1755\n",
      "Eval Loss  : 122.5891\n",
      "\n",
      "Epoch 99\n",
      " 10.300639 seconds (6.01 M allocations: 234.119 MiB, 1.40% gc time)\n",
      "Train Loss : 122.1673\n",
      "Eval Loss  : 122.5902\n",
      "\n",
      "Epoch 100\n",
      " 10.346804 seconds (6.01 M allocations: 234.767 MiB, 1.36% gc time)\n",
      "Train Loss : 122.168\n",
      "Eval Loss  : 122.5976\n",
      "\n",
      "Epoch 101\n",
      " 10.337076 seconds (6.01 M allocations: 234.723 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1681\n",
      "Eval Loss  : 122.6156\n",
      "\n",
      "Epoch 102\n",
      " 10.368752 seconds (6.01 M allocations: 234.119 MiB, 1.49% gc time)\n",
      "Train Loss : 122.1619\n",
      "Eval Loss  : 122.5928\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "\n",
      "Epoch 103\n",
      " 10.373433 seconds (6.01 M allocations: 234.753 MiB, 1.49% gc time)\n",
      "Train Loss : 122.1614\n",
      "Eval Loss  : 122.5708\n",
      "\n",
      "Epoch 104\n",
      " 10.377207 seconds (6.01 M allocations: 234.801 MiB, 1.49% gc time)\n",
      "Train Loss : 122.1516\n",
      "Eval Loss  : 122.5265\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 105\n",
      " 10.328398 seconds (6.01 M allocations: 234.122 MiB, 1.41% gc time)\n",
      "Train Loss : 122.1602\n",
      "Eval Loss  : 122.5905\n",
      "\n",
      "Epoch 106\n",
      " 10.297312 seconds (6.01 M allocations: 234.686 MiB, 1.37% gc time)\n",
      "Train Loss : 122.1625\n",
      "Eval Loss  : 122.5685\n",
      "\n",
      "Epoch 107\n",
      " 10.298175 seconds (6.01 M allocations: 234.782 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1722\n",
      "Eval Loss  : 122.5613\n",
      "\n",
      "Epoch 108\n",
      " 10.306001 seconds (6.01 M allocations: 234.138 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1424\n",
      "Eval Loss  : 122.5648\n",
      "\n",
      "Epoch 109\n",
      " 10.417319 seconds (6.01 M allocations: 234.762 MiB, 1.36% gc time)\n",
      "Train Loss : 122.1443\n",
      "Eval Loss  : 122.5704\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "\n",
      "Epoch 110\n",
      " 10.406468 seconds (6.01 M allocations: 234.776 MiB, 1.37% gc time)\n",
      "Train Loss : 122.1442\n",
      "Eval Loss  : 122.5719\n",
      "\n",
      "Epoch 111\n",
      " 10.408033 seconds (6.01 M allocations: 234.052 MiB, 1.37% gc time)\n",
      "Train Loss : 122.1406\n",
      "Eval Loss  : 122.6375\n",
      "\n",
      "Epoch 112\n",
      " 10.400269 seconds (6.01 M allocations: 234.773 MiB, 1.36% gc time)\n",
      "Train Loss : 122.1454\n",
      "Eval Loss  : 122.5768\n",
      "\n",
      "Epoch 113\n",
      " 10.411657 seconds (6.01 M allocations: 234.790 MiB, 1.40% gc time)\n",
      "Train Loss : 122.1591\n",
      "Eval Loss  : 122.5379\n",
      "\n",
      "Epoch 114\n",
      " 10.391858 seconds (6.01 M allocations: 234.119 MiB, 1.35% gc time)\n",
      "Train Loss : 122.1434\n",
      "Eval Loss  : 122.5524\n",
      "\n",
      "Epoch 115\n",
      " 10.412166 seconds (6.01 M allocations: 234.748 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1587\n",
      "Eval Loss  : 122.519\n",
      " -> New best loss! Saving model out to vae_mnist.bson\n",
      "\n",
      "Epoch 116\n",
      " 10.364388 seconds (6.01 M allocations: 234.734 MiB, 1.46% gc time)\n",
      "Train Loss : 122.1341\n",
      "Eval Loss  : 122.5309\n",
      "\n",
      "Epoch 117\n",
      " 10.305328 seconds (6.01 M allocations: 234.128 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1451\n",
      "Eval Loss  : 122.5648\n",
      "\n",
      "Epoch 118\n",
      " 10.307783 seconds (6.01 M allocations: 234.753 MiB, 1.38% gc time)\n",
      "Train Loss : 122.154\n",
      "Eval Loss  : 122.5439\n",
      "\n",
      "Epoch 119\n",
      " 10.317588 seconds (6.01 M allocations: 234.782 MiB, 1.39% gc time)\n",
      "Train Loss : 122.1413\n",
      "Eval Loss  : 122.5686\n",
      "\n",
      "Epoch 120\n",
      " 10.371357 seconds (6.01 M allocations: 234.133 MiB, 1.41% gc time)\n",
      "Train Loss : 122.1414\n",
      "Eval Loss  : 122.5575\n",
      "\n",
      "Epoch 121\n",
      " 10.363115 seconds (6.01 M allocations: 234.695 MiB, 1.38% gc time)\n",
      "Train Loss : 122.1524\n",
      "Eval Loss  : 122.6002\n",
      "\n",
      "Epoch 122\n",
      " 10.371094 seconds (6.01 M allocations: 234.782 MiB, 1.40% gc time)\n",
      "Train Loss : 122.1517\n",
      "Eval Loss  : 122.5814\n",
      "\n",
      "Epoch 123\n",
      " 10.352795 seconds (6.01 M allocations: 234.119 MiB, 1.39% gc time)\n",
      "Train Loss : 122.1515\n",
      "Eval Loss  : 122.5475\n",
      "\n",
      "Epoch 124\n",
      " 10.361391 seconds (6.01 M allocations: 234.773 MiB, 1.39% gc time)\n",
      "Train Loss : 122.1342\n",
      "Eval Loss  : 122.5565\n",
      "\n",
      "Epoch 125\n",
      " 10.356074 seconds (6.01 M allocations: 234.785 MiB, 1.37% gc time)\n",
      "Train Loss : 122.1594\n",
      "Eval Loss  : 122.5542\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "################################# Learn Parameters ##############################\n",
    "\n",
    "import Flux: train!\n",
    "import BSON: bson\n",
    "\n",
    "θ = params(g, f)\n",
    "optimizer = ADAM()\n",
    "L2_f() = sum(x->sum(x .^ 2), params(f))\n",
    "loss(X) = -L̄(X) + 0.01f0 * L2_f()\n",
    "\n",
    "num_epochs = 200\n",
    "early_stopping_patience = 10\n",
    "learning_rate_schedule = 5\n",
    "\n",
    "best_loss = nothing\n",
    "last_improvement = 0\n",
    "epoch_train_loss = Float32[]\n",
    "epoch_eval_loss = Float32[]\n",
    "\n",
    "for epoch_idx in 1:num_epochs\n",
    "    println(\"Epoch \", epoch_idx)\n",
    "\n",
    "    @time train!(loss, θ, zip(train_data), optimizer)\n",
    "\n",
    "    train_loss = mean([-L̄(x) for x in train_data])\n",
    "    eval_loss = mean([-L̄(x) for x in eval_data])\n",
    "    push!(epoch_train_loss, train_loss)\n",
    "    push!(epoch_eval_loss, eval_loss)\n",
    "    println(\"Train Loss : \", round(train_loss; digits=4))\n",
    "    println(\"Eval Loss  : \", round(eval_loss; digits=4))\n",
    "    \n",
    "    # If this is the best metric we've seen so far, save the model out\n",
    "    if best_loss === nothing || eval_loss ≤ best_loss\n",
    "        println(\" -> New best loss! Saving model out to vae_mnist.bson\")\n",
    "        bson(\"vae_mnist.bson\",\n",
    "            encoder   = cpu(g),\n",
    "            decoder   = cpu(f),\n",
    "            epoch     = epoch_idx,\n",
    "            loss      = train_loss,\n",
    "            eval_loss = eval_loss\n",
    "        )\n",
    "        best_loss = eval_loss\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in N epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement ≥ learning_rate_schedule && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement ≥ early_stopping_patience\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "    \n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAAAGQCAYAAABWJQQ0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXRU9f3/8dedmcxkmewhIZBAAmEHCaAIgmGRAgJitVDcUNCv2orVWoWvWqt+/bVqi1WrhtYuil9rlW/doNYNRCJYxQ0EZA0khD2BhOzbzNzfH2g0JoQAycyQ+3yck3OY9/3MzXuih5MXn+UapmmaAgAAAAA/sAW6AQAAAADWQQABAAAA4DcEEAAAAAB+QwABAARMWlqa0tLSAt0GAMCPCCAAcAbLz8+XYRgtfmVmZga6zXa3ePFiGYahhx9+ONCtAABOwBHoBgAAp69nz5666qqrmr3WuXNnP3cDAMDxEUAAoAPIyMjQ/fffH+g2AAA4IZZgAYDFGIahsWPHas+ePZo1a5bi4+MVERGhsWPH6j//+U+z7zly5Ihuu+02paeny+VyKTExUbNmzdLmzZubHV9XV6c//OEPGj58uCIjI+V2u9W/f3/94he/UElJSZPxlZWV+sUvfqGuXbvK5XLprLPO0ssvv9ymn/u7CgoKdN1116lr165yOp1KSUnRddddpz179jQZe+DAAd16663q1auXwsLCFBcXp0GDBummm25SWVlZw7jS0lLde++96t+/v9xut6Kjo9W3b1/NnTu32fsCgFUxAwIAFlRSUqJRo0YpOTlZN9xwg/bt26clS5Zo3LhxeueddzR27NiGsUeOHNGIESOUm5ursWPH6rLLLlN+fr5efvll/fvf/9by5cs1cuTIhvE1NTWaNGmSPvjgA/Xq1Utz586Vy+XSjh079Kc//UlXX321YmNjG8bX19dr4sSJKi4u1qWXXqqqqiq99NJL+vGPf6y3335bEydObNPPvmPHDo0ePVqFhYW66KKLNGDAAH311Vd65pln9MYbb+jDDz9URkaGJKmqqkqjRo1Sfn6+Jk6cqEsuuUR1dXXatWuXFi9erAULFigqKkqmaWrSpElau3atRo0apcmTJ8tmsyk/P1+vvfaarrnmGqWmprbp5wCAMxUBBAA6gNzc3OMuwRoxYoQmT57cqLZhwwbNnj1bzz33nAzDkCRdd911GjdunK6//npt27ZNNtuxSfIFCxYoNzdXd911lx588MGGe8yZM0eTJ0/WNddco61btzaMv/fee/XBBx9o9uzZevbZZ2W32xveU1pa2ui1JO3fv1/nnHOO3n//fTmdTknSFVdcoQkTJujRRx9t8wDyk5/8RIWFhXr66ad1ww03NNT//Oc/68Ybb9RPfvITrVixQpL03nvvKS8vT7fddpseffTRRvcpLy+Xy+WSJG3atElr167VJZdcoldffbXRuNraWtXX17fpZwCAM5oJADhj5eXlmZJa/Lr11lsbvUeSabfbzYKCgib3mzp1qinJXL16tWmapllbW2uGhYWZ8fHxZmVlZZPxkyZNajTe4/GYUVFRZnR0tFlcXHzC/rt3725KMnft2tXstbi4uFb9HJ599llTkvnQQw+1OK6goMCUZPbv39/0+XyNrvl8PrNfv36mpIafzbJly0xJ5t13393ifTds2GBKMq+44opW9QsAVsYeEADoACZNmiTTNJv9evzxx5uM7969e7NLgs4//3xJ0vr16yVJW7duVXV1tYYPH67w8PAm479ZqvXd8WVlZTrnnHMaLbNqSUxMjNLT05vUU1JSdPTo0Vbdo7XWrVsnSRozZkzDzM83DMNQVlaWJOnLL7+UJGVlZalz58566KGHNHXqVC1atEgbNmyQaZqN3tuvXz8NGjRI//jHP5SVlaVHH31Un376qbxeb5v2DwAdAQEEACwoMTGx2XpSUpKkY0ulJDVssv6m/n3fHPH7zfhvAkPXrl1b3Ut0dHSzdYfDIZ/P1+r7tMbJfp7o6Gh99NFHmj17tj766CPNmzdPgwcPVrdu3bRo0aJGva5cuVLz5s1Tbm6ubr/9dg0fPlydO3fWAw88QBABgO8ggACABRUWFjZbP3TokKRvQ0FUVFSj+vHGfzMuJiZGkrRv3762a7YNneznkY49rf25555TUVGR1q1bp9/+9rcyTVPz5s3Tiy++2DAuISFBTz31lPbt26fNmzfrqaeeUnx8vO677z797ne/a8dPBQBnFgIIAFjQ7t27mz0advXq1ZLU8PT0vn37KjQ0VJ9++qmqqqqajM/JyWk0vk+fPoqKitKnn37a7HG7gfZNnx988EGTZVSmaTb5/N9lt9uVmZmpBQsWNASPZcuWNRlnGIb69eunefPmafny5ccdBwBWRQABAAvyer365S9/2eiX8JycHL355pvKyMjQeeedJ0lyOp26/PLLdfjwYT300EON7rFixQq99dZbysjI0KhRoyQdW4p04403qrS0VLfeemuTpUelpaWqqKho5093fN26ddO4ceMajt39rmeeeUZfffWVxo8f37A/ZtOmTdq9e3eT+3wzUxIWFiZJysvLa/aZKN8fBwCQDPP7/wQEADhj5OfnKz09XT179tRVV1113HHfPaLXMAydddZZKikpUXJyssaPH6/9+/frpZdekqQmzwEpKirSiBEjtGvXLo0fP17nnntuw3NAQkJC9M4772j06NEN42tqajRx4kStXr1avXr10oUXXiiXy6Vdu3bp7bff1po1axpmGNLS0ho+x/eNHTtWOTk5TWYqmrN48WLNnTtXQ4cO1aBBg5odc8UVV2jixInatm2bRo8erSNHjmj69Onq37+/Nm/erGXLlikhIUFr1qxR7969JUmPP/64br/9do0aNUp9+/ZVfHy8du3apWXLlskwDK1Zs0ZDhw7V66+/rksuuUTnnHOOBg4cqM6dO2vfvn16/fXXVVlZqaVLl2rq1Kkn/BwAYAmBOHoLANA2WnMM7/f/qpdkjhkzxty9e7c5c+ZMMzY21gwLCzOzsrLMNWvWNPt9ioqKzFtuucXs3r27GRISYiYkJJgzZswwN27c2Oz4mpoa85FHHjEzMzPNsLAw0+12m/379zdvv/12s6SkpGFc9+7dze7duzd7jzFjxjTp/Xi+OYa3pa/HHnusYXx+fr45d+5cMzk52XQ4HGZycrI5d+5cMz8/v9F9N2/ebN56663mkCFDzPj4eNPlcpk9evQw58yZY27evLlh3J49e8w777zTHDFihJmYmGg6nU6zW7du5owZM8y1a9e26jMAgFUwAwIAFmMYhsaMGaNVq1YFuhUAgAWxBwQAAACA3xBAAAAAAPgNAQQAAACA3zgC3QAAwL/Y+gcACCRmQAAAAAD4DQEEAAAAgN90mABSVVWlL774QlVVVYFuBQAAAMBxdJg9IFu3btWwYcP0m9/8Runp6Y2uVVVVKTw8vMl7TqbeFveg3rb1YOrFavVg6sVq9WDqxWr1YOqFevD1YrV6MPVitXow9dJSfcuWLXrggQea1CV1nCehf/7556Yk8/PPP29y7ciRI82+52TqbXEP6m1bD6ZerFYPpl6sVg+mXqxWD6ZeqAdfL1arB1MvVqsHUy8t1f/xj380WzdN0+wwS7AAAAAABD8CCAAAAAC/IYAAAAAA8JsOswkdAAAA8IfS0lLl5+eruLhY0dHRzV5vr3p73vtk6jabTZ06dZLL5Woy9kQIIAAAAEArvfvuu7r44otVU1MT6FaCwujRo/Xcc8+pR48erX4PAQQAAABohdLSUl188cUaN26c7r33XjmdzkC3FDAej0c7d+7U3XffrczMTBUVFbV6NqTDBxDTNAPdAgAAADqA/Px81dTU6N5779WIESMC3U7ADR8+XKmpqTr//PO1fft2DRo0qFXv69Cb0H2mqa7/8OiDQnugWwEAAMAZzuv1SpKlZz6+75uHENbX17f6PR06gBiSDtdI28s79McEAACARWVmZiozM1P9+/eXw+FoeD1r1qyTvtekSZOUn5/f9k1+T4degmUYhmJd0tE6I9CtAAAAAG1u/fr1ko4tDzv77LMbXjfH4/HI4Tj+r//vvPNOm/fXnA4/NRDjlMrqCSAAAACwlhUrVmjYsGG6+eabNXLkSC1btkzPP/+8hg8friFDhmjIkCF6++23G8anpKRo69atko6dbnXnnXfq/PPPV48ePXTzzTe3WV8degZEkmJdho62fkkaAAAA0GpVHlNbj7bf/fvGSOGOU//H9PXr1+upp57SU089JUk6fPiwrrrqKhmGoV27dmn06NHas2eP7Pame6bz8/O1atUq1dbWqm/fvrrmmmt0zjnnnHIv3+jwASTGKZWyBAsAAADtYOtRadhrnna7/+eXODQ04dTf369fP40cObLh9a5du3TllVdq3759cjgcOnz4sPbs2aO0tLQm773ssstkt9sVHh6uwYMHa+fOnQSQ1oh1SXvLCCAAAABoe31jjoWE9rz/6XC73Y1e//jHP9ZTTz2ladOmSZKioqKO+1DF0NDQhj/b7XZ5PG0TtDp0ADFNU3PWLdQT8TMk9Qp0OwAAAOhgwh3Gac1Q+NvRo0cbZjsWL16s8vJyv/fQoQOITFP99q5WT1t/EUAAAABgdY8//rimTZum1NRUnXfeeeratavfe+jQAcSw2VTvjJCjrirQrQAAAADtJi0tTYcPH25UmzBhgiZMmNCoNmfOHM2ZM6fh9W9/+9uGP+/du7fhz2vWrGn0vtdff73Neu3wx/B6XREKra+QzzQD3QoAAABgeX4LILfccovS0tJkGIY2bdrUUDdNU/fff7969+6tgQMHauzYsQ3XqqqqdPnllysjI0O9e/fWq6++etLf1xfqVpS3QqV1bfEpAAAAAJwOvy3BmjFjhhYsWKDRo0c3qj/xxBPauHGjNm3aJKfTqQMHDjRce+SRR+RyuZSbm6u8vDyNHDlS48aNU2xsbKu/rxHqVnRNpY7WHjsRCwAAAEDg+G0GJCsrSykpKU3qCxcu1G9/+1s5nU5JUnJycsO1JUuWaN68eZKk9PR0ZWVlaenSpSf1fe3hbkV7K1TCDAgAAAAQcAHdA1JWVqaioiK99tprGjFihEaMGKElS5Y0XC8oKFD37t0bXqelpamgoKDFe1ZUVKisrKzhyxYapihfpUpq2QMCAAAABFpAT8Gqr69XXV2dqqur9fHHH6ugoEAjR47UgAEDNHDgQEmSYXz7EEGzFRvJx4wZ0+j1y7fPUaJN2llcoeKwxg9PKSkpafYezdVPZix1/9SDqRer1YOpF6vVg6kXq9WDqRfqwdeL1erB1Is/66Wlpc1ex7GfTXFxcavGBjSAxMfHy+1266qrrpIkdevWTaNGjdJnn32mgQMHqlu3bsrPz1enTp0kSbt379aUKVNavGdOTo4yMzMbXtevWaa97y2TJ8StuLimEz5xcXHN3qe5+smMpe6fejD1YrV6MPVitXow9WK1ejD1Qj34erFaPZh68Vc9Ojq62WuQoqOjj/uz+76AH8N7+eWX6+2335Z0LF1+8sknOuussyRJM2fOVHZ2tiQpLy9POTk5mj59eov3c7vdioqKavhyRcUo2luho7W+9v0gAAAAQACkpaWpb9++yszMbPjavHnzKd1rzpw5euqpp9q4w8b8NgMyb948LV26VAcPHtSECRPkdruVm5urBx98UHPnztWiRYskSXfddZeGDh0qSZo/f76uvfZaZWRkyGazKTs7u9XJ6hu2sAg55FN5ZY0kd1t/LAAAACDgXn755YYtDMHObwEkOzu7YTbjuxISEvSvf/2r2fdEREQ02pR+KmzhkZKk2soKEUAAAABgBb/+9a916NAhPfnkk5KOHdTUrVs3bd++XQcOHNBNN92kyspK1dTUaPbs2brrrrv81ltA94D4gxF2LHTUVVYEuBMAAAB0NL66GnkO7Wm3+zuSUmVzhp5w3IwZMxQa+u24ZcuW6eyzz9bvf/97OZ1O/fOf/9S4ceOUkJAgl8ulFStWyOVyqbq6Wuedd55+8IMf6Oyzz263z/FdHT6A2MIiJEkeAggAAADamOfQHhX+/mftdv/E25+UM7XXCcc1twRryJAhWrZsmWbMmKFnn31WCxYskCRVV1frpptu0vr162Wz2bRnzx6tX7+eANJWvlmCZVYTQAAAANC2HEmpSrz9yXa9/6maO3euFi9erMzMTOXm5urCCy+UJN19991KSkrSunXr5HA4dOmll6qmpqatWj6hjh9Avp4BUQ0BBAAAAG3L5gxt1QxFIFxyySW65ZZb9PDDD2v27Nmy2+2Sjp08O3DgQDkcDm3btk3Lly/X+PHj/dZXhw8ghiNE9XaXHLUEEAAAAHRM398D8uSTT+r888/XzJkztWjRIm3ZsqXh2j333KPZs2frhRdeUFpaml/Dh2SBACJJ9c5wOWorZZpmoyerAwAAAGe6/Pz8415r7iTaIUOGaNOmTc2OX7x4cRt21ryAP4jQHzwut9yeCtV4A90JAAAAYG2WCCCmK1xR3kqV1Aa6EwAAAMDaLBFAjLAIxfgqCCAAAABAgFkigNhDj82AHK0zA90KAAAAzlDfnCJVV1cX4E6CR1VVlSQpJCSk1e+xxCZ0R3iEor17mAEBAADAKUtLS1NoaKgeeOAB3XvvvXI6nYFuKWA8Ho927typu+66S5GRkerdu3er32uJAOIKj1CUt1IHCasAAAA4RdHR0Vq6dKkuvvhivfXWW4FuJyiMHj1aK1eulMvlavV7LBFAQsLDFe2rUEktS7AAAABw6iZOnKiDBw8qPz9fxcXFio6ObjKmtLS03ertee+TqdtsNiUmJsrpdCohIaHJ+JZYIoAYoRGK8NWotMYjyR7odgAAAHAGi46O1uDBg1VcXKy4uLgm19uzHojveaL6ybLEJnSFhkuSqssrA9wIAAAAYG2WCCBGqFuSVFtZHuBOAAAAAGuzSAA5NgPiqaoIcCcAAACAtVkigCgsQpLkrSaAAAAAAIFkiQDyzQyIqtkDAgAAAASSJQKInGHyGTbZapgBAQAAAALJEgHEMAzVOyPkqCWAAAAAAIFkiQAiSV6XW666Snl9PIwQAAAACBTLBBBfqFtRvgodrQt0JwAAAIB1WSaAGGERivYSQAAAAIBAskwAsYdHKtpbqZJalmABAAAAgWKZAOIMZwYEAAAACDTLBBCX261oX6VKagPdCQAAAGBdlgkgoW63opgBAQAAAALKMgHEHh6pKG+lSmp8gW4FAAAAsCzLBBBbWIQc8qmisjrQrQAAAACWZaEA4pYk1VbyNHQAAAAgUCwTQIyvA0gdAQQAAAAIGMsEEFv4sQDirSKAAAAAAIFiuQDiq64McCcAAACAdVkngHy9BMtWUx7gTgAAAADrskwAMewO1TtCZathBgQAAAAIFMsEEEnyuCIUUlsh0zQD3QoAAABgSZYKID6XW5HeClV5At0JAAAAYE2WCiAKcx97GnptoBsBAAAArMlSAcQW5la0t0JH6wLdCQAAAGBNlgogjnC3on2VKqllDwgAAAAQCJYKIK4IZkAAAACAQLJUAAl1R7AHBAAAAAggSwWQkIhIRXsrVFLHEiwAAAAgECwVQGzhboWbtSqrqg90KwAAAIAlWSuAhLklSdWVPA0dAAAACARrBZDwYwGktrIiwJ0AAAAA1mSpAGKERUiSPFUEEAAAACAQLBVAbGGRkiQfAQQAAAAICIsFkGMzIGY1AQQAAAAIBEsFEMMVJp9hk72GAAIAAAAEgrUCiGGo3umWvY5TsAAAAIBAsFQAkSRvqFthdRWq9/EwQgAAAMDfLBdATFeEonyVKq0LdCcAAACA9VgugBjhbkV7K1RSG+hOAAAAAOuxXACxh0cqylupo3UswQIAAAD8zXIBJCQ8QjHMgAAAAAABYbkAEup2K8pXqaMEEAAAAMDvLBdAXBFf7wFhCRYAAADgd5YLIPZwt6K8lSqpIYAAAAAA/ma5AGILc8sunyqrqgPdCgAAAGA51gsg4W5JUm15RYA7AQAAAKzHegEk7FgAqasqD3AnAAAAgPVYLoAYX8+AeKuYAQEAAAD8zXIBxBYWIUkyqysD3AkAAABgPRYMIMdmQIwaZkAAAAAAf7NcADHsDtU7wmQngAAAAAB+Z7kAIkkeV4RC6ipk8igQAAAAwK8sGUB8oW5FeitV4Ql0JwAAAIC1+C2A3HLLLUpLS5NhGNq0aVNDfezYserRo4cyMzOVmZmpxx57rOFaVVWVLr/8cmVkZKh379569dVX26aZ0AhFeytUVm+0zf0AAAAAtIrDX99oxowZWrBggUaPHt3k2hNPPKFp06Y1qT/yyCNyuVzKzc1VXl6eRo4cqXHjxik2Nva0erGFRyqqtFJHCSAAAACAX/ltBiQrK0spKSkn9Z4lS5Zo3rx5kqT09HRlZWVp6dKlp91LSHiEon0VKq0jgAAAAAD+FBR7QObPn69BgwZp1qxZ2rVrV0O9oKBA3bt3b3idlpamgoKCFu9VUVGhsrKyhq/a2tomY1xut6K9FTpMAAEAAAD8ym9LsI7n+eefV2pqqkzTVHZ2tqZNm6bNmzc3XDeMb0OC2Ypjq8aMGdPo9YIFC3TDDTc0qhl2u2K8lXr/SI2Ki5vuRC8pKWlVjXpg68HUi9XqwdSL1erB1IvV6sHUC/Xg68Vq9WDqxWr1YOqlpXpLAh5AUlNTJR0LGjfffLPuuOMOHTlyRPHx8erWrZvy8/PVqVMnSdLu3bs1ZcqUFu+Xk5OjzMzMhtcul0uVlZWKi4trqJXHJyraV6EjZoTi4iKavc93x7dUox7YejD1YrV6MPVitXow9WK1ejD1Qj34erFaPZh6sVo9mHppqX48AV2C5fF4dOjQoYbXr7zyipKSkhQfHy9JmjlzprKzsyVJeXl5ysnJ0fTp01u8p9vtVlRUVMOXy+VqMsYWFqFQX50Ocg4vAAAA4Fd+mwGZN2+eli5dqoMHD2rChAlyu9368ssvNXXqVNXW1spmsykhIUHLli1reM/8+fN17bXXKiMjQzabTdnZ2SedsJpjC3dLkkrKqiVFn/b9AAAAALSO3wJIdnZ2w2zGd3322WfHfU9ERISWLFnS5r3YwiIlSRWVlW1+bwAAAADHFxSnYPmbLezYvg9fdZWqPSfe2A4AAACgbVgygBhfL8GK8VaooCLAzQAAAAAWYskAYo+MlWnY1Ln+iAoqmAEBAAAA/MWSAcSwO2SPjldKfaF2MwMCAAAA+I0lA4gkOeIS1ct3iBkQAAAAwI8sHECS1N1TqN0EEAAAAMBvLBtA7LGJSq4rZBM6AAAA4EfWDSBxSYquKdG+srpAtwIAAABYhmUDiCMuSTb55C09Iq+PZVgAAACAP1g2gNhjEyVJSbWFOlgd4GYAAAAAi7BsAHF8HUBS6wo5CQsAAADwE8sGECPEKTMiRl3r2YgOAAAA+ItlA4gk2WMSlO7lKF4AAADAXywdQIyYBPXwMgMCAAAA+Iu1A0h0J3WtYwYEAAAA8BdrB5CYBMXWHNbeck+gWwEAAAAswdIBxBbdSXbTq+qS4kC3AgAAAFiCpQOIEZMgSYquLFRpHcuwAAAAgPZm7QASfSyAcBQvAAAA4B/WDiDOUCk8Sqn1PIwQAAAA8AdLBxBJColPUmo9J2EBAAAA/mD5AOKIS1JPH0uwAAAAAH+wfACxxyYqhRkQAAAAwC8sH0AccUnqVFOoPeW+QLcCAAAAdHiWDyD2uEQ5fB5VlJQEuhUAAACgwyOAxCVJkkLKClXvYxkWAAAA0J4sH0AcsccCSJe6Qu2rDHAzAAAAQAdn+QBiC4uQGepWSt0hNqIDAAAA7czyAUSSHHGJSqkv4iheAAAAoJ0RQCSFxCWph/eQdpczAwIAAAC0JwKIjs2AdPMUqaCSAAIAAAC0JwKIjp2ElVhbqN1lBBAAAACgPRFAJDliE+Xy1qq0tDTQrQAAAAAdGgFE3z4LxFdcKNNkFgQAAABoLwQQfRtAOtUU6khtgJsBAAAAOjACiCRbeKR8zjCl1BdyFC8AAADQjgggkgzDkD02USn1hRzFCwAAALQjAsjXnHGJ6lZfyFG8AAAAQDsigHzNEZ+kdG+hdpcHuhMAAACg4yKAfM0Rm6TOdYUqqPAFuhUAAACgwyKAfM0el6RwT5UOl1QGuhUAAACgwyKAfM0emyhJ8h49FOBOAAAAgI6LAPI1R/yxZ4FElB9StTfAzQAAAAAdFAHkazZ3jHwOp7rWF2lflRHodgAAAIAO6ZQCSF1dXVv3EXCGYciISVRq3SHtKCeXAQAAAO2hxd+0n3/+eT355JMNrzdt2qRevXopPDxcY8eOVWFhYbs36E+h8Ynq4SvSFyX2QLcCAAAAdEgtBpCFCxfKZvt2yM9+9jM5nU49/vjjOnDggO6+++52b9CfHHFJyvAV6vNiAggAAADQHhwtXczPz1f//v0lSYcPH9bq1av1xhtvaPLkyerUqZPuuOMOvzTpL/a4JCXVrtEXxXb5TFM2g70gAAAAQFtqcQbEZrM17Pd4//33FRISonHjxkmSkpOTdfjw4fbv0I8ccUly1ZbLV1utrUcD3Q0AAADQ8bQYQAYPHqxFixbpq6++0hNPPKHx48fL5XJJkgoKCpSUlOSXJv3lm2eBpNQXam2hGeBuAAAAgI6nxSVYDz74oKZNm6azzjpLkZGRWrFiRcO11157TcOHD2/3Bv3JkZgiSRpvy9PHhT00t0+AGwIAAAA6mBYDyKhRo1RQUKDt27erZ8+eiomJabh23XXXKSMjo90b9Ce7O1qOTl01tm6LHiwcJ4nN6AAAAEBbajGASFJkZKSGDRvWqFZXV6cpU6a0W1OB5Ezvr365W7WxRKqsNxURwkZ0AAAAoK3wHJDvcab1U0zJboV6qvX5YfaBAAAAAG2J54B8jyu9vwzTpxH1O/QxG9EBAACANsVzQL7HkdRNcoVpmrZqTeHgQLcDAAAAdCg8B+R7DJtNtpReOqd6i9YWMQMCAAAAtCWeA9IMe0pvpRzZqv0VPu2tIIQAAAAAbYXngDTDltpLjpyX1bNun9YWpSnFzUlYAAAAQFvgOSDNsHXtKRk2/cC7RWsLu+tH6YHuCAAAAHSjuJMAACAASURBVOgYWlyCJX37HJDo6GiVl5fLNI8tSZoyZYp69+7d7g0GguEKV0hymsZ7tmotJ2EBAAAAbeaEASQnJ0fjx49XWFiYYmJiFBYWpgsuuECrV6/2R38B40zvr35lW/TZYVMeHyEEAAAAaAstBpDly5drwoQJOnTokO666y4tWrRId955pw4dOqQLLrig0Z6QjsaZ3k/RpXvlrCnXppJAdwMAAAB0DC3uAbnnnns0ZcoUvf766zKMbzdi33ffffrhD3+oe+65RxMmTGj3JgPBlXbs+SfDarZpbeFwdeuYB34BAAAAftXiDMjGjRv105/+tFH4kCTDMPTTn/5UGzZsaNfmAske31m2yFhd6NvCE9EBAACANtJiAHG73dq3b1+z1/bu3Su3290uTQUDwzDkTO+nc2vYiA4AAAC0lRYDyPTp03XnnXfqnXfeaVR/99139ctf/lIXX3xxuzYXaK60/kot2aYdJV6V1Qe6GwAAAODM1+IekIULF2rjxo268MILFRUVpaSkJB06dEjl5eU655xztHDhQn/1GRDO9P6ye2rVtyZPXxR3URr7QAAAAIDT0mIAiY2N1UcffaQ33nhDa9asUUlJieLi4jR69GgNHjxYy5Yt09VXX+2vXv3OmZIh2R0aXbdVnxWn6tJANwQAAACc4VoMIJJks9k0ffp0TZ8+vVH9lVde0dy5czt0ADFCnHKm9tIFNVv11+LJgW4HAAAAOOOd8EGEbeWWW25RWlqaDMPQpk2bmlx/7rnnZBiG3njjjYZaVVWVLr/8cmVkZKh379569dVX/dVuA2daPw0o36LPS2wNT4EHAAAAcGr8FkBmzJihNWvWqHv37k2u7d27V08//bRGjBjRqP7II4/I5XIpNzdX77zzjm666SaVlPj3qYDO9P6KrCyUo6JEu8r9+q0BAACADsdvASQrK0spKSnNXrvhhhv02GOPyeVyNaovWbJE8+bNkySlp6crKytLS5cubfdev8uV1k+SNKxqiz44wAwIAAAAcDr8FkCO549//KMGDBigc889t8m1goKCRjMmaWlpKigoaPF+FRUVKisra/iqra09rf7s0fGyxyVpsm+LVu73nda9AAAAAKtrsgk9MjKyyZPPm+PxeE77m+fl5ekvf/mLPvzww+OO+W4vrdmDMWbMmEavFyxYoBtuuKHZscdbztWk3qWnzt7zlR7c59WRI2X67o+n1feg3ub1YOrFavVg6sVq9WDqxWr1YOqFevD1YrV6MPVitXow9dJSvSVNAsjtt9/eqgDSFj766CPt379f/fodW+Z08OBBXXfddfr1r3+t66+/Xt26dVN+fr46deokSdq9e7emTJnS4j1zcnKUmZnZ8NrlcqmyslJxcXHNjm9NvaJPprpsflollfUqdsSqV7Rx3LHU/VsPpl6sVg+mXqxWD6ZerFYPpl6oB18vVqsHUy9WqwdTLy3Vj6dJALn//vtP6gan44orrtAVV1zR8Hrs2LG64447NG3aNEnSzJkzlZ2drcWLFysvL085OTn605/+1OI93W63oqKiGtUqKytPq09n+gDZfF4Nq96u9/dnNgkgAAAAAFrHb3tA5s2bp5SUFO3du1cTJkxQRkbGCd8zf/58VVdXKyMjQ5MmTVJ2dvZJJ6y2ENIlXQqP1AzzS/aBAAAAAKfhhA8ibCvZ2dnKzs5uccyqVasavY6IiNCSJUvasavWMWw22dMHaPTB9Xr4wFUyTdNvy9QAAACAjiTgp2CdKezpg5RUvEPVFRXacjTQ3QAAAABnJgJIK9l6DJRh+nR+1Ua9zzIsAAAA4JQQQFrJFtNJjoQuutT7pd7ngYQAAADAKSGAnARX7yEaXrZe7+835WvFM0kAAAAANEYAOQmuPkMUU75PoeWF2lgc6G4AAACAMw8B5CSE9hosGYbGVX/JPhAAAADgFBBAToItPFIhqb10cT37QAAAAIBTQQA5SaG9hyizdL0+2O+V10cIAQAAAE4GAeQkuXoPUVhNqZLLd2vdEQIIAAAAcDIIICfJld5fCnFpfNWx07AAAAAAtB4B5CQZIU65egzQ1Lr17AMBAAAAThIB5BSE9hmifke/0sf761TPYVgAAABAqxFAToGr91A5vLXqU7ZV60v4EQIAAACtxW/PpyCkS7qMiChNqF6n1UWOQLcDAAAAnDEIIKfAsNkU2nuIJtZ8qTVF9kC3AwAAAJwxCCCnKLTPEHUvy9XWQ9Wq9bIZHQAAAGgNAsgpcvUeIpvp05DyjfroEAEEAAAAaA0CyClyxCXJntBFP6her+X7CCAAAABAaxBATkNo7yEaW0UAAQAAAFqLAHIaQvsMUWLVAR3Yd0jFNYQQAAAA4EQIIKfB1WuwTMPQ6Mp1em8/AQQAAAA4EQLIabCFR8repaem1a7T8n08Eh0AAAA4EQLIabL1PEvDy7/Ue3s8Mk1mQQAAAICWEEBOk73HQIXVVSiqaKd2lgW6GwAAACC4EUBOk61rhuQK05jKdXqXZVgAAABAiwggp8mwOxTaK1NT69Zr+V6WYAEAAAAtIYC0gdC+Q9WndIs+3lMpj48QAgAAABwPAaQNuPoMlc30akDpJn1SRAABAAAAjocA0gYcCV1kj0vSD6rXsQwLAAAAaAEBpA0YhqHQPkM1oWq9lu8jgAAAAADHQwBpI66+w5RUuVcFew+prI4QAgAAADSHANJGQnsNlmnYdF7Fer2/nwACAAAANIcA0kZs4ZFydeutKTXrWIYFAAAAHAcBpA25+gzViIov9d7e+kC3AgAAAAQlAkgbCu07VOF15XIe2qU9lUag2wEAAACCDgGkDTm795VcYRpTsU6rCh2BbgcAAAAIOgSQNmTYHQrtNVhT69ZpVaE90O0AAAAAQYcA0sZC+wxV37Kt+uRAvQ5WsRkdAAAA+C4CSBtz9R0mu8+j4ZWbNPBlj17J8wW6JQAAACBoEEDamCOhi+yxiXo05lNlJRuascKr2e97dLSW2RAAAACAANLGDMNQaN9hcuZ/qZcvsOl/x9q1bLepga949O5eZkMAAABgbQSQdhA6aKTMIwdU8tyDuqJLhTbNcKhfjKFJb3l1z5euQLcHAAAABAwBpB2E9R8u54xbVLvjSx367U/Uac/neudCux46x6Y/5jr1SSEzIQAAALAmAkg7cfQfoaT//pNCuqTr8NP3qPSVbN3Rt07dwn166isCCAAAAKyJANKO7NHxSrjx14qZMU9Va5fr8O9v1oLor7Rkl6miajalAwAAwHoIIO3MMAy5R1+kxDuekhEWoemr7lcnT4n+uo1ZEAAAAFgPAcRPQpJS1enG38gwDD1kvqU/bvbJ42MWBAAAANZCAPEjW0SkHEPGaszuf6uovEZvFBBAAAAAYC0EED9znDtZtpoKLfC+z2Z0AAAAWA4BxM9ssUkKO+s8XXnoda3c59WWEmZBAAAAYB0EkABwj5uh8NL9mlH7ibI3MwsCAAAA6yCABIArra+c6f01v+x1PbfDp7I6ZkEAAABgDQSQAIkcN0PJRV+pT9k2Pb+DWRAAAABYAwEkQEIHnitHQhfdV/26sjf7ZDIJAgAAAAsggASIYbPLPfZSZR78jyoKD2p1kT3QLQEAAADtjgASQOHDJ8ge7taCimX64w6nfEyDAAAAoIMjgASQzRmqiFHTdNHh5Vq7r0YXvuXVvkpCCAAAADouAkiAuc+/SHbTqzejlmljialBr3j0fzvZlA4AAICOiQASYPbIWEWcfYG6bVim9YM3aUIXQ7NWejX7fY+O1jIbAgAAgI6FABIEoqbNlS05TXV/u1t/qX9Rz2dJy3abOusVjz5kczoAAAA6EAJIELC7o+W68i5FTb5K5e++qEkr7tHGSWXqEWVoxpowrdrPkiwAAAB0DASQIGHYbIqadKUSbnpI9YcK5Miepzd6btDIBK9+uNyrjcUsxwIAAMCZjwASZEJ7DVbS/EUK6dpDR//8Sz3neUHpblOT3/KooIIQAgAAgDMbASQI2SNjlXDjrxU16SrZV7+sN2wvyGU7FkKKawghAAAAOHMRQIKUYbMpavKVCvnBlTJzlui90JdUVCNd9K5X1R5CCAAAAM5MBJAgFzJyqqIvuk4hOf9QTsQSrT9i6oqVXnnJIAAAADgDOQLdAE4s8oKZMr0e6c3ntGq0XSMLZui/PKF6cISpAXFGoNsDAAAAWo0AcoaImni55PNKbz+nlec5NPPwdA18xaMxyYZu6mfTJemGQmyEEQAAAAQ3AsgZJHLSlTK9HvVY/jd9MfqIPh56mZ7Ic2vWSq+Sw6Ub+to0K9lQXKAbBQAAAI7Db3tAbrnlFqWlpckwDG3atKmhPnfuXJ111lnKzMzUOeeco/fee6/hWlVVlS6//HJlZGSod+/eevXVV/3VblAyDENRU645FkT+8y+d++xsvVq8UJuHbNQPu0mPbPBp5LsRWprPgwsBAAAQnPw2AzJjxgwtWLBAo0ePblR/7LHHFBMTI0lav369JkyYoKKiIhmGoUceeUQul0u5ubnKy8vTyJEjNW7cOMXGxvqr7aBjGIaiL5wtz8DRcu74XJUfv6PIdXfrV3FJum/YRP28dox+uDxJtw409bvhNjntLMsCAABA8PDbDEhWVpZSUlKa1L8JH5J09OhRGca3vzAvWbJE8+bNkySlp6crKytLS5cubf9mzwBGRLQix89Q0l1/VqdbH5UrY7A8Of+nhZ/cqpdSvtCizT6N/pdXeWUclwUAAIDgERTH8N55553q2bOnLr30Uv3zn/9sCCEFBQXq3r17w7i0tDQVFBS0eK+KigqVlZU1fNXW1rZr74FmGIZc6f0Vd8UvlHzf32VL6aVR796vL+NfVnG1V0Ne8+iVPJZkAQAAIDgExSb0hx9+WA8//LBWrFih+fPn68MPP5TT6ZSkRjMipnnif80fM2ZMo9cLFizQDTfc0OzYkpKSVtdPZmwg69WTr1PEhvcVueo5rez9lean/FwzVkTr5jSf/mdYcdD02Rb1YOrFavVg6sVq9WDqxWr1YOqFevD1YrV6MPVitXow9dJSvSVBEUC+MWHCBN18883auHGjhg0bpm7duik/P1+dOnWSJO3evVtTpkxp8R45OTnKzMxseO1yuVRZWam4uObPhjqZelvcwy/1S29Qde+zVPz33+kPR+9U1shf6ubcFI3qYddlPZtOegVd/x3xv0kHrAdTL1arB1MvVqsHUy/Ug68Xq9WDqRer1YOpl5bqxxPQJVgej0c7duxoeP3JJ5+osLBQPXr0kCTNnDlT2dnZkqS8vDzl5ORo+vTpLd7T7XYrKiqq4cvlcrXfBwhiYQNHKPH2JyWbXT98+xe6z/UfXfeBVxuL2RMCAACAwPFbAJk3b55SUlK0d+9eTZgwQRkZGfJ6vZozZ44GDhyowYMH6+c//7lefvnlhlOu5s+fr+rqamVkZGjSpEnKzs4+6YRlZSGduirxtsfl6j1E1335iKZqqy5d7tHRWkIIAAAAAsNvS7Cys7MbZjO+68MPPzzueyIiIrRkyZL2bKvDs7nCFH/NnTrwhzv0+9zfaHL3R3T1qs56faJdNoMjegEAAOBfQXEKFtqX4XDK9eNfyBEaqtcP/T+tyqvUb9ZxMhYAAAD8jwBiEUZElBKu/x+FVxbpnbKFeuCzer21hxACAAAA/yKAWEhI5+6Kn3uPUg9+ob9V/k1XrPRqSyn/CwAAAMB/guoYXrS/0D5DFfOjeRr/zyd1na2rRq+Yqoyoeo3rYmh8F5vGJRtKCj+2N6TOa2pHqbSpxNSmElO5ZaZ+3MWuSzgHAAAAAKeIAGJB7lFT5Tm0Rz9f82dNPbtKH0Seq38eSNFfth47Hat/jOTzhSu33CPP1wdmdQ6T3A6f3iwI0+AupnpEsYEdAAAAJ48AYlHRP7xevspS9fr07+pl/q/+KzRcZmpf7Y7tpzVGX3nMeg2JLlL3mn2KLd8v49A+eUuK9ELidF228lqtucgup50QAgAAgJNDALEow2ZX3Oz/lvmD2YooL1Jd3mbV5W9R+qZl6l71wrFBdocc8clyJHaVY9B5MuvrdOWaV/WxI0P//ckYPTbSHtgPAQAAgDMOAcTiDGeoQnsNVmivwZIk0zTlKdqn0vJyxaf1lmH/NmSYpqmao0f06LYn9YPP0zQmOU0/TGMTOwAAAFqP3x7RiGEYCklMkS02qVH4+Oaac9p/KSwuQS8efFg3raxQfjlPVQcAAEDrEUBwUgxnqOLn/krJdYX69b5sXfaeR3VeQggAAABahwCCkxbSuZviLvu5Jh7JUf/t/9bdnx57oKHXZ2pPhak1B316IdenRzZ4lVfBRnUAAAB8iz0gOCXhQ8eqNm+z7v/wr7p4bS/9c2eG9ld/e2yvJDltkt2I0EPDvfrZAJtsxvHDyGdFPj2z1afZqTaN5DkjAAAAHRYBBKcs5uLrVVewTS8VPqwPYmcqNbJencxKxfgqFempkFlXo+fDztfPPxqll3eZemaMXb2iG4eQzSWmfvWpR1Ff/EvzC1/QI13mqHTWVE1OZXIOAACgI+K3PJwywxGi+Dm/VJTD1IVfLNKgz/9XXba8q4iC9dLRg1JpoS775GFt1mMqLy/XWa949NhGr7w+U7srDV2zyqOsl47ox/95QP/v4J8V0zVFD+zN1gsvvqHHN3plmuwtAQAA6GiYAcFpccQmqvO9i1VcXKz4TomNrpmmqaJVSxX1zvP6t3O9Xhn8M/3847P1l60+5ZZGaHLden2891GFGR7FXf8/Cu0/XAdffFwPfbJId79p6vqSqVo0igceAgAAdCTMgOC0GXaHDHvTLGsYhhyDs9T5zqfl6tpTl67+H202/qABzjK96n1Wi3b8StEp3dV5wR8VNuDcY8f8Trpa7qwf6sEDf5T58Rua8KZXRdXMhAAAAHQUzICg3dljEhR/wwOqWvuujNef1mOb35ckRU+7Vu5xP5Jh+zYHG4ah6EtulGw2/c+qP2mh3ath5dM1vYtLWak+nZtoqJv72LjvKqsztbHY1JfFprYfdioj3qs0t6H0SENpkVJEiLVmUarKyuTz+gLdRkD5KstlVpZKcZxqAABAMCGAwC8Mw1DEiEly9RmqipX/VH3vsxU5aPhxx0ZffL1kGJr//l/UL9KrhXumKHuHV5KUFCYN72QoLdSlPbUefVlsam9pvQbU7NI51VvVz3dAXzhS9ayrp7aEpqnaFqpOoVKX0HDFh3sUFSJFOaWoEENRTinBCNGcCFOxrjM7pNQcOaR1Oavl2bBa6Ue3qdCZoPX9L9CwiRMV26VroNvzK9NTrz1/mC+VFili7t0K7Tss0C0BAICvEUDgV47YTor50U0qLi5ucZxhGIqe/l+SYdO0lc9omvGsFJOossguKqjroo3lXbSt3q2p3nzdVblVSSW5snvrJUeIjOgEzTzyjuT1yJShqtgUHYzuoYKQTnJ4auWsKZertlxhdWVy15erSiF6cPn58gy+QLOGJevcRKPJDEtJral395p6a49P1bWheuBcU31iAh9YPEeLtG/Vu9r51SdKPrJNnYwQfRk3TIWjblHd7q0avOFfqly/RJvjByhm5ET1Oz8r0C37xaG3XpJZtEefh/XV8Kd/pZgf3iB31sVN/rueSN3eXFWueUP1kfEyJ18hw25vp44BALAOAgiClmEYir7oWoUNGqnSnVvkrDqq0MP7FFf0lQYeXi7V18kemyhnWj85zx8jV1o/hXTtoZKycsVGuVV/YLfq9+2Ue+9Oxe7bqYyDG2WPiJQtIkq2TpGyhfeQLTxKJYWHdNPWVxXy7j+05sOztKTrBeo3arR6RNj0aV6ttm7ZJce+Lcqs2qZ5tdtUJ7vu2ni5Og0fo/vPdig53P9BxPR6tfWNl+XK+bvCTGl91FB9MWK+Rmadqx91cUuSiotHqNp2k1at+FBhG5Yr9Y3HtfPNP+rIyFk6d8ZlJ/3L+Jmifn+eale+pL8mzdCuITO0/pMXdONrf1L9/jzFzpwnw+Fs8f2maao2d4PK3/s/1W79XDUR8XJVFatwy8eKnfVzOVN7+emTAADQMRFAENQMw5Arvb8c0Z0V8521/KbPp+KD+xTfJbX59zmccqb2kjO1lyK+rhUXFyuumf0AvuJixUTcpsr1qzVk9XKN3v6YynP/pB2ubppZk6dQs04+m0O2rhly9xipiv279cSOR7TlyKu6ev0cnTtymBYMPrnzHI7UmDpUbSjGNFt8QGNzCvPzlPfco+pcslOvd71YceMu1qwhSc2eFtY1JlRXzrhAnkvHa8VXh7T37X9q8ofPaVX+dg2/8TZFREU1+z1M09TOzz7Twf8sV3Sv/oqdOFWGI+Sk+gwE0+vVzsWPap+ziwZccoVuS6jU3zpfr9veTdPCT59SfeFeJVz7q+bf6/PJs+0zFX38pup2b1VJbLp+l36HXgwbrYE1O/WXw0+q/tFb5R57iaIunC2bM9TPnw4AgI6BAIIzkmGzyQiNOPHAVrK5whR57kT1OXeiPIcPSB8uV4+9u5XQb4zC0vvKmZIhI+TYv5z7iosVcXS/bEuf0bO77tWHhYN10efXaHC/bsrs7FOPSKlHlKGu4ZLdZsg0pR2FVfpq8w4V526V68B29SjbIYfp1euuzjoSkazqqM4y45IVmpAsd1yMRjpMpUc23mzv8Xi04u8vqOfnL6ralaw1Fy/UvDH9VXa05IRHFTtshiYP6izfwJv1/KsDNOw/i7T11/Nku/wuDRnSv9HYbZt3aP+rf1Wvw1/KdCYrNu8Dbfng/+QePV0p46bKFhHZZj/3tnZw+SsKK9ypf5+3UL/v7VRJSaUWDLbrJfdEXfbvrvrr3t/I8/tb5DjnByr11ctbVixvWbF8ZcXylh6Rr6pcRUkD9EDGfXrDNUzX9rUrN9Omf+1I1bSNj+nqQ6/p5g9eVPWXHyp21i1Sp7RAf2QAAM44BBDgexwJyUq5+GqFFxc3mnX5LlePgUr++e9V89XHGrXsWY3a+gttK+ihctOlw4ZNBw27fIZdTodd8TVF6lGzR2fLpxqbS4VxvaSB56vONJVcfkTdSgrk3v2J3LllDfc/bI/WstCuKo9OkdEpRZHx8Ype+7IyKnfrP71n6ILZV2pspOukP5vNMHTRuEwVDn1KB599WD2fm6+XN1yji674kbbvOaJDf/uLhu17XyGhKVo78Ve64IKReiFnm3yfvKUp772g/PdflOuciXKdPa5dTpfyHDmomu3rVH9wr6p7nyVn976yu6Nb9d66Q3tU/e7f9VLSdN15Uf9G4e2ynjZ1mTlAM//9qJ7Y/Vv1Wfl/Ko+IU3VYnCrDYlUWNVCH42P1TN0A5TgH6No+Nu3ItCkt8tg9rkzz6LJ+kbpj7Y81dtMoPX34KfX/491yXnKTNGZ6m/8cAADoyAggwCkyDENhA0eqa//hqvpspfpv/UIOu0MVtT5V1nlUWetVdZ1XVTG9dKDXxeo1oK+6pnZXxtcbmb+/JMxXXSnP4f3avX27vIeLFXdwrxKLdyrh4AcK89UoL7y7jsx5TFdk9jnt3vumd1aPXy3Ue4sXa8S6Z5Sz/QP1qNqtMEeENp5/s8ZdNFmhzmN/PVx+dpKc427TXz67Wodz3tCsT99U3Mf/0q7QKHkSUuVITJU7OVWRXVLkc0XJjHQ3zBadiFldoar1X6l2+zqVb1knW8kB+WRTuSNC9TmvHBsTl6yI9L5ypvWTL6GbzNjYJvtXTNOnHYsfV7EjXn0vvVqJYU1nhLKSbXptRrIufHOh8iskfX0Pd4gUFSJFhkgj4uq041xHQ/D4rk5hhp4b69DKXqn6yerf6Hcb/lvpX3yiRAIIAAAnhQACnCbDZlfE8B+oNmOY4uLi1Ol714+39+T7bGERcqb2UnxEvHp9d7+LaaqqpFihXp8SOn3/7qfOGRKiC6+/Xps+Hqy4f/9VuwZdrKxZl2twRNOlbe4QQ7eNTNDRodfo8XU/1ta1a9W5Yo8yyvcq4/B29Vy3UnVmnSRpn6RqZ6Q87jg5ouPljo2TERKiYl+9PJVl8lSUy1dVpv/f3p2HSVGdix//VvW+zD7DIoODIoKgIAENWwgucC8KqAQX1Ai4sbkRWUxMbjQqIpjovUZNXNHHC0QTiEt+cYsKivuNC4Ji0IiyDLP0bD29VtX5/VHdBcPMAIMsA7yf52mbfqk+dU5V0dbbZ2kVa4BYA3EU3/q78FrwB7xb1g9v977kB918t62G4NYv6R9bz+D16+n5zzdxK4MtHY4mZ+BpBH8wAndxZwAib79K3ta1LBlyJ3f0DLba5l75Gl9c6GH91lrKOuQTdtvD5LIikQYKc3Y9tO/0LjqfTvDwP1v6ccKWF1CW1eS3bIQQQgixa5KACNHOaZpGqLCI5G6WLt5bJw46FQadSiQSwd9C8rGjfJ/GLYOCRI7vRzB3BFtjsCWm+KTRoqaiktrv/k0y2kCqthpPNEKH6ggdyzeRbzVS6wpT48qh1tWZGldPasI5bC0o5pviExl4XCfOPlpj1lEaIY+WSdq6UpUoZdXW0/jbVsUvNifI++5TzqtbyeiX/oT//z2BWdqLgpOHoL2xjGdKRvOzcSfvtr0+l0ZpUJHn3ftVwPxuDc+xfQl9u4x0+Td4jzp2r8sSQgghjjSSgAgh9orfrXFMLhyTqwE6dO9MpKfP6e1JGIov6+CLWsWblY0U5QYJuTVK3dDTDSEPeJP1DCrLa3VJ4GK/xvhjNMYfAxBi7eZerK7/IfO+jsH69zm7ZiWn/e1JqtwF9Dj/Cor8B25p4W69e5Fa6aZi3aeUSgIihBBC7DFJQIQQ+4XfrdG3CPoWaUQK0hQWNv8Rv0jEatPvkXQOKK7uonP1CWFi/3Ea/9g8gns21FNIjFuOD+/L6u/W4NIAbwd60P3zNZSeee4B3bcQQghxKJMERAhxSAq6NcaWaYwtyycSsQ74/jsFNb7I60OfTa+glDpsf9hRUH2K6AAAIABJREFUCCGE2Ndk5qQQQuylRJfehJJ1GNu+O9hVEUIIIQ4ZkoAIIcReKu5+HAY69V9+erCrIoQQQhwyJAERQoi9NLCzl08DPdi2bs3BrooQQghxyJAERAgh9tLxORYf55yIe+MalFIHuzpCCCHEIUESECGE2Eu6Bo1dTyQYj2BUbTnY1RFCCCEOCZKACCHE91B8/ImY6CT+JfNAhBBCiD0hCYgQQnwPPzw6xFr/sVR8LvNAhBBCiD0hCYgQQnwPp5RovB8+EfNrmQcihBBC7AlJQIQQ4nsIuDWqOp9EsLESM7LtYFdHCCGEaPckARFCiO8pt0cfLDSSG2QeiBBCCLE7koAIIcT3NLBrLp/7u1HzhcwDEUIIIXZHEhAhhPiehnbUeDd4IvGvJAERQgghdkcSECGE+J46BjW+KT6RQH05Rm3lwa6OEEII0a5JAiKEEPtAoPuJAKQ2SC+IEEIIsSuSgAghxD7Qv6yA9b6jafhSJqILIYQQuyIJiBBC7APZeSDRf0kPiBBCCLErkoAIIcQ+0Csf1uSfiK9mM6qh5mBXRwghhGi33Ae7AkIIcTjQNQ2920nwb0gsuYuqwo5ovgCaP4DuC6L5AqQNi4bcPDSPF83tyTx7MaINxEOhzC+pK7DsX1Q3TUjFu+IK56GH89Bc8pEthBDi0Cf/NxNCiH3kpLJCFh01hXlF/wIsrFg9VmQbKhlHJWOYyQT1poFKp0BZTd5b3UqZFTv8WQ/moAJhtvkC4PbYSUzmkbYU1f4AmssFLredrLhcpFJparwesCywLJRlgbJIplLU5hehh3LQg7nowRz0UA5m0iAVzQM00DIPNKx4AhUOoXl9++fgCSGEOGJIAiKEEPvIsI4awwvGc+awGKcfm0vQDZqmOX8fiUQoLCwEQJkmKp1EGSlqa2spKCiyb/Z1DTQdlEVkyyZyXWBGa7EaajGjtcSqKvC6dTDSqB0fqRhWzECZBlim/WyamOkUKY8XdB00HU3XQXehUikSW/+NFWvAijWAZTr1rGjWMttmQA/n4SrogKugBHd+B9K6h/pQKFN2pu6aTjpaT52uZZKvOFYmCUsbFjWFJeg5+eihPFw5+ejhPMxYnERVEGUYYBko0wQjjdFQT2MgYLfJspzndDJJY34hmteH5vWjeXzoXj9WMo3p1dEDOXYythNlpDCjdVjROqxYA2YsQTrZGc0fQg8E0bwB+xjtgrIsrIYajJpKzNoK0hVbiXfsgiu/BFd+MXpOwW7LEEKII5kkIEIIsY8MLNEIuGDcqiCsMtCAsCfzcEOOK0jHsEGRDwp9GkV+H4U+H8m4i3BDEA3N7nQAXBp40p05tiRMh3yNkgDkesCoqaEgk8TsaMfkpq1xpRQqGcNqbKC2opzc3Fy7h0bZQ8FQirrKbQTNJGZtBWZNJUZNBYkv/g+jsQ4TDZRlDyHLvE9pGpY/ZA9D8wXQ/QE0XxCVjpPa8rWTUJFOOXVKtnJcnS00O3nSdB1lpKnZqRcpa2t2c3/Q7tkJhDHiUTbHGlCJWLPtt+34QtPRMj1MW31+NLcXzeOxh8qZJltjDZi1lWAaO7xHozp7rABcblx5RahgLpWBILia9lYlDZOI1wuoJsc4aRjUFhTbdc70SOnBXMzGGPHvLDtxyhw3K1pLKpGgprgTrrwiXLmFuPKLceUWYsUSpJP1dtKXSqCSCVQqgdHQQCwv3+4dc9u9ZJrbi1kTIb7JhZWIoRIxrMwjFa13es+UZTq9aCm3j2jpMbiLOuMuPgpXYYddDg9URhqjpgKrvgazIYJZX4PVWI+he0ke0xN3hy7oobwmyfruKNPArKvG2vIdhpVEzylA9/n3+P1CiINLEhAhhNhHAm6ND89z8/HmevDnEE1DNK2IGtCQhvL6FFHlZmMU/lllUZ2EmiQYlg+FhWpeIrC9Z8KrQ4E3RK43TcgDQbdG0A0hN+imn4DPQM92omA/mykfhWHTSYLCHsjxaBgJN8EaC0uBqcBSAUwVIJkI0jM3TJewRmkIQh77ptAVLia0PxKfVAKroZbaSDX5RcXgctk3xi43uNzU1NVRWFQCut7kBrW6uprCvFxUKmn3JKWTWKkEddu2EnZpds9OPJrp4YmiLAiVdEQP2z0urnAeejCH2uoqcrxu+8Y73oiVaEQlGonV1+H3uFHpFMpIodIpzHic4PEn2zf6BR1wFXTAXVBCTTxFvs+NWVuZeVRh1lQSqypH1zWUmQYjjRWLowwDlUxgeDyZ4W04w9xUMkFiy1dYjZleqR0SrCSArqOH83GF89Fz8lGGQerrzzDrIliNdU2Oc6KVazTSStxJ/twedH8IzR/A0lx275nLZSdmLhdoGmZtNbXvv7S910zXcRV0wNJ0tqLAzPbAGZn2xojvuDNNRw+GsRobqMxc9VogjLukC+6So0hZUOP3g+7KnHcdUCQrt1IRq8eorcSqr3GOT3m2WK8PPacAVzgfw+2jUse+PlIJrHQSlUpipVMksnOwMg/cHkwFFR4vaJp9nWXOieEPkRg+Dt9xfduUIAkhdk0SECGE2Id6F2h0UiaFhc2H4EQiSQoLQy3Em96sK6UwFHxVXovhz6cyoaiIQ2VC8V1NEssTIGZAY1oRMyBmQF1Sw2XaX6hbCizsP8fTLlK1FlGDTEIEKQt2Tm62axrP80JpCHJdATxuo9nWlhkg7DPwu8DvBp8OfpdGKuVDcxukLHt/KROSlp0odc0z6Rgg8/DRMdAR5QlQ4srDo4NXsx8eoN6Koxs6SoFCOUlaXVrDbblxe9y4vCHcOng0cPnzCbSS+OS0ENd1P74W4ulIhLyd4pEWYgBaIoIrk9RQepwTN79PcmZZ9tC1xnpqI1UUdumGFgg1GdrVZHsjhVkXwayrpj5SRW5xB3SvP9MD5Ufz+qmpraMgNwdlpDPJgT18ry4apaDjUXYvldu7R/UsyMvDrK3EqNqCUbUVo3oricZG/KEwmtuNpm/vZYnjIrdTKXpuIa7cAvRQLpruonpbOblWAqNiE+nKzRgVmzGqt6LiMVIuPdPjYqIyiYYK5ODu2BVfzx/gKijBlVdMo6UR9uhY0TrMhlqshhrMaC1mXQ16MGQfA68PzeND8/qIp9IEvJ7tQxfTKTDSJGJR3F6v3XsH9r4B67t/UXX/PNydjiY8dAzBU85E9webHRMhRNtIAiKEEO2Mpml4NOjgVxQW2t/EZkUiKQoLw83eE4nUU1gYaCXe9CYyZSq2VNVQXFiAK9Njomv2sK8tlTUkfAVsalRsjsGmqP28tV7hb2H+eTypUC5ImFAft5+TpiKVdhH02QmJ12X33vh0qE9pvFthsS0OFXG798UWAponOJDTprhPDxNwpwm6cR4Bt0YiFSRFmrgBcRPihp0QhVwhivxpCv0ahT4o9EGBV4O0j7yQub3uLkjGPWhek4Y0mYRO0ZCG+rif4pBBgc8uoyBThpZ0U9Bg4dLtY5t9JBp1uumKosy2br35N+uarqMFQihfkJTyYfjD6ICuFBo0+zZec3txF3XCXdQJV36kxaRKc8davHnWPXYC1Raay+Xsj552LBKJkN9KMudvqT4eL57CTng6d2PHK7ctvWrxVspurQwjEiG3DdtXV1cTqv6Oxreep3bFH6h74XGCp5yBWXYSiao8mgyjA8xoI8m6Ijvh8XgzDx8qWodhJjJzoeLOs9FQTyzXTshwue1nXceMJ0g1ltjzm3ZIoJTV8rDDHSnTcHoGrYYaTFfTOioUVl0NhkptHzqZSfasmgiphkqUmbbnY5n2vDIzFidZWJRZ/MJulxVtxHQpO2l1e+yhinrzeVet1tPpAa3B9LqcVQFbmru1P2SH8ZkN9pDG7Fy7dDxBrENn9FAuemYFQleobf8+2jNlpLDimeGWVRWk042Z4ZiezJcGmQRdqf3a6ycJiBBCHGG8Lo1cD4Q9zf/nEnRDaZ7GcXlN/y4SSVBY2Pzm1U5wWou3dKO3PW4pRSQJ22KwOVJHIJRLyoL0Dr0mDdEoOeGwMzfGvvmGuoYogWAYMzOEzFBgWBBpaETzBp2eIfuhsNIm+SEPATcEXBDI9NZU1CdJuAJEEnZdNjXCpxGLWMqNgUXKgqRp1ydt+gh5rO1zerwaYTfoSuObBvio2qImM6wubkLrvUxNk618LxT5wa8FSak0MXN73ZMmtJZsubQwXj3tJEke3X7WVQiPO20nPE7yo2GZQbweAz1zDHXsxNMyAwS8Bh4duydJB7cG8aQfy2WQyCRsCRMSpsJDkJKgkUnYtidd8ZgHt990zl229ysa8+HxmZhKYVr2+VKA2/TRMdck32v3tOV7NXK9EI+6yI9bTmKczc82V7swIha1SUVtyj7O1VEfBSHTmWuVk7murYSbwgYLd6Yt2bY1NugUGFYm4dac8hvqdYp1ZW+feY9bB8PSKDr+ZPzHn4xRW0nj2/+PxndexHrrhVbnLFW2Eo+3Em9tWFxri0Fs0nT7ZtHlRnPbQxWtdJq4mUalk07vTdbWVsopbyXe2vC9ltrVrGxdB7eXRCCE7g+h+4NomT+nLEWVkcjc8NsLQah0snk5mo7m8aB0F4lMQmYvbqGh6TqWpdiqa5k5Z5mlyxVYlkmipflolkVc05ztwE7CSKeanRPN60dZFhEjRTMuNwl/MDOnLZjpXQySNtJU6nrTBUAsE1NpVIbCmSTSj+4LoHl8pJIJajyezIIapj1k0TJJRRuoVKY9byuVwEom7OGlaJR7fU1WPjQsRYVGkyGiKp3CMlIkXG77eLlcmYTWhWWZbEknseIxMNN7dL4367q9KIfPn+lN9WMqjW1O76Rl905aFqZpUK67dhhWmvlP2YhWSpcERAghxEGiaxrFfij2Q2esVoatGW2MpyksbP4Nqp34tDT8rbUepebfiLf+zXzz3qeEodhYUUtufr5z0519VETqMP25RJJQnYDqpLKfoykKw54mvTdBt0YqHiUUCttD6zIPBdQ2NOINBJskbGkL6mNJvL5Ak32aFsQSJl6f23l/tqxEUqG57SQubUFj2n62DI1cNxT5wB+0e5J8Lo3axhSNuKlMwPo6i0gSIklA+fC5LCchyiZFmnLhdVu4dc3pBdKAuoSLaKVFbQpqk+wwBypIy4mbHXdrmV4mH/g1F6kayxle2JDO9qrtKvnbfVKY5dXDnNnF4NxuOmOPLqbTWZPIHXUx1d9sID9/h+WqATSN2poIecGAc0Noz09K0RCN2sPifH40X9C+GfUFqKmroyAvL3Mjajg3pLXVleQG/M77s3NZonU1BH0+p2ciO5QskUoTzM3b3vPi9aN5PEQbY4Rzcsj2oma/0W6IRsnJy7Nv9jXNucmvb4yRV1iIll04IbOcd011FfmhkH2zmxm6Vh+pIhzwN1uRr7E2gl/HmVelEo1YjfX2AhB5RXhLj8v0LOTjCufRmLYIB/1OudlyYg11BPyBTCKRveFVxGONBIKhHdpjX1DxeIJAsxX5NGKxOMFQ03/7mqYRSxvkdCrNrMRnzw3TvX67Jy8ctJOkxnp7eF+0lmh1JQGXvbKflYhlerJiaGjofr/Tg6W53KC7SMSi6GR6eeojGMk4Kp3ENC1nblW2xwvdhdJ09HAuWn6xneR4/WgeL7HGKH6Pu8lxNuMx3MGQ08OW/V2peDJNIODfPnwxs3hEPB4nmF9oJ07+YGaeV5CGeJLcsL36oDM000wTra0h6HHbqximMj13qSSJxijeQCCzIEhmVUVNJ5FM4ff7miyqAar1lUWQBEQIIYTY5/xujRK/ojDYvJepyGwt2WptjlBbk63WkqrWyt9VL1ZLw/r2bC7T9njDHvWGRdNQl4Lqmlpy8/K3J1zY9zNmrJZjOuQ3Wd5657KVUiRN2FRZQ05egdMzln2uqqkjJzcPCzsps7B7ZWrqGgjl5DTZ1lSwpryRVyoDTHvLZKqCQR00zinT6RfqTFc9z+l5CbntYXo6HjwttLW1oWJaPIkeaH4sdc2Lt4XtE5EI4RbiZitznOKRSItzomKt1McVibS4Xz2tcO8Ud+W3XHaqlblSrV0fiVbqmG5luJzZSvmtDa9Lt3JsUq3sF0D3+tEL/VDY0Ykl2zh8b1/FjRaGNrZ1iKHZSjwWaXm4ZmvXWSQSaXUVxpaGX7J0afNYhiQgQgghhDiodM0efpXrhVBKUZjbPHGLKOWsytYaTdPwu+25PC0lfyWWlZlX5bzDLtvT8sIRQ3PS/OKHOVQlFH/7VvHsRotb/2kRN5v3mLg0CLnDhD1pJykJezRCbrCMAKZuZIax2fOkEiYkjBBKSzsJT/ZZJ4zfncbnAr/LTm58uoZhBrG0dLNeL6VCuF1p9Ew9snO6lBXE6043GYrn0sAwgrh3WlRC0XIcsIfvuY0mw+JMI4DX03xbIx3A7zVwZYayZYcCmmk/Lo/htDHbM5dMB5x9KrZ/iZ5KB9BchjPE0lQKwwJlBsnxG017Cl1gpX34fOb2cjJ9asmED5+/eT2TCR9+v+msGpgdlhhP+PD5zR16GxWWgsaEH91tOD2FaStzvowAQZ+xfRiky36OJXzoboO02n6eDAXK8JMXyCzc4dLs4aAuiMW9maGKmaTZstvcmPDj9hhNejQTST9Bv+EMFbSfNYyUj4C/eQ9fPOHD7TUxLNVkyGoi6cfrbX5sUik/Pl8L5zblJxyw2+p1aU5PZzzhBY9JwlTOPLuEAZc0K2E7SUCEEEIIIXah2K8x6XiNScfrxA3Fh9/V4Q7mOkO/sosSVNTFUN4gjZlV5xrTikYD4qaiwI9z0+lzafhcYKaS5AQD9o36Djfs0VgM3RskaWXm3hiQtBSppEk44MncANo3uh4d4vEkPn8gs6T29hvVWDyFx+fZaRigXY7PZ98C7jjPOJkw8fmb3xomEiYer9sp38Ieuuf1NtuUhK5we7JJg50omSYkUxo+ti/G4NPB5YYACp9vexKQrU46pQj67W3dOrg0HZcGsUQK5XY786Qq4tjHOOXC7bbQssPNMuUZhgt3Y/N6pg0Xrqi9tp7acVii6cLjtjIJyfbfZsLSCXi3z5Hy6PZcsoSpSFt2XZw5bCYoy0XA0/Q8+XSIKY2qROYm3bRIZOZXYXnweiznGsgOWcTS8XmaLmRhmhrJpJ1EZBObtKVIpl24XM0XKjBNF36Pcq4xdyYhNQ2NFk4hqbSGp4V4MqVRaWSTX8tJgk3TQ8hn2QlVJmkO7CbDkARECCGEEGIPBdwaffJaG0a3qzlILQ1za2243L6ay7SrYXffL77roXttGdLX1nJ21aZdD/Xbs/juhwzuef33bM6YHd/VHLOdh2Dt+aqHdnxXbWqtnLbEW677LkZg0fxfjxBCCCGEEELsJ5KACCGEEEIIIQ4YSUCEEEIIIYQQB8xhk4CkUqkmz1nJZJK77rqLZDK51/F9UYbE9228PdXlSIu3p7ocafH2VJcjLd6e6iLx9leXIy3enupypMXbU112F//zn//cLO5Qh4mVK1cqQK1cubJJvK6uTgGqrq5ur+P7ogyJ79t4e6rLkRZvT3U50uLtqS5HWrw91UXi7a8uR1q8PdXlSIu3p7rsTTzrsOkBEUIIIYQQQrR/koAIIYQQQgghDpjD5ndAEokEAF9++SXh8Pa1sKPRKAAff/zxXsf3RRkSl3NyuMTbU12OtHh7qsuRFm9PdZG4nJODHW9PdTnS4u2pLnsSj8Vi5ObmsjNNqeyP3h/annjiCSZPnnywqyGEEEIIIYQA3nnnHQYNGtQsftgkIFVVVbz00kt069aNQKD5rzQKIYQQQgghDpxevXoRDDb/pfjDJgERQgghhBBCtH8yCV0IIYQQQghxwEgCIoQQQgghhDhgJAERQgghhBBCHDCHdAKybNkyJk6cyCWXXMLFF1/M0qVLW9zu7rvvBuC1115j+vTpfPzxxwA89NBDALzwwgvMmzePN998k/PPP5+//OUvALz88su8/PLLvPTSS4wdO5aXX34ZgFWrVvHNN98wefJkLr74YlatWgXYK3G9+uqr/OQnP+Giiy7i/vvvB2DYsGE8/PDDzpJkWQsXLmTy5MksXryYCy64gLlz5wKwevVqLrzwQs4++2x++tOf8uWXXzrvefvtt/nTn/7E6tWrWz0ulZWVLcaTyWSz2NatW1vc9r333msWa2hoaFJ2KpUC4PXXX+f5558nlUrxr3/9q8XyYrEY69evx7IsnnvuuSb73bJlCx988AFVVVVN3tPe2wq0ub1HUlth37f3SGorHJ7tPZLaCodPe4+ktsKR9RklxMFwSE9CnzZtGn/4wx+c1zNnzuT+++/n4osvdmJKKf7v//6PL7/8kvHjx/PYY49xxx13cNZZZ/HMM8/wwAMPcO6557J48WJGjRrFO++8w9VXX82jjz7KwIEDueiiiygpKXGW+b3sssuYPn06qVSKO++8k/z8fCZNmsTSpUu59tprAbjvvvsAuP766/nv//5vrrrqKsaOHcuyZcvIzc1l8uTJDBo0iCuvvJJHHnmEMWPG8MILLzB9+nQefPBBpk2bxgMPPMCvfvUrbrrpJqZPn85TTz3FzJkz6dOnD0cffTTffvstn332GQ888IDzgZRt73XXXccf//hH5s6dy3fffUevXr349a9/zYwZM3jggQeYOXMm6XSaQCCAaZpomsZ9993HxIkT0TTNOWYDBw5kyZIl3HXXXXTt2pXnn3+e/Px8CgsLueOOO5g1axb5+fkUFxdTWFjIK6+8wptvvslJJ53EuHHjuPDCC50VyS688EL69+/P+++/z4QJE1i+fDl//vOfWbBgAeXl5Xz33XcUFBQwcOBApk2bdki09bHHHqNHjx573N6BAwceMW3dV+c2Ly/viGnr4Xpu77333iOmrYfruV2zZs0R09Yj7TPqiy++4N577yUajZKTk8O1115L7969m91vPffcc4wbN47y8nJWrlzJmDFjCIVCvPHGG4wYMYKNGzeybt06+vfvz+OPP8748ePp2bNnk2N23333ce211+L1eikvL6egoIDHHnuMaDTKZZddRseOHXn77bfp0qULt912G8lkkmnTpjF06FBuvvlmJk+eTI8ePZrU69VXX+Uf//gHF198MQsWLGD06NFceumlVFZW8vDDD7N582Z69uzJVVddRSAQOCjtjUQiR0xbd3Vud3ZI94Ck02leeukl1q1bx8svv+z8GGEwGGTJkiUsWbKEpUuXcsYZZwBQXFxMfn4+ixYt4tVXX3W+fejcuTP5+flce+21uFwuZ7mwVatW0dDQQDAYpFevXlx22WUArFu3jvLycjp06IDX63V+YCUvL49oNMpDDz3En//8ZxobGwFwu92MGzeOJUuW8Otf/5rXX38dsJcOXrx4MalUivfee49IJAJAbW0tFRUVRCIRcnJyyMnJAUDXdWbMmMGYMWOYMWMGPp8PgL59+zJt2jTnke2RqaiocNo/d+5csrlmY2MjDz30EJs2beL3v/+9Ez/55JM566yznPcsWbIEgG+++YbXXnuNpUuX8uCDD1JdXQ2AYRjU1dUxc+ZMJk6cSG5uLmeeeSZPP/00ubm5TJkyhZkzZwKQn5/PTTfdBMDFF1/sXIzfffcd9957L926deORRx7ho48+2mVbTzrppHbTVqBN7d3btk6dOvWQa+v3Obc7tvdIauvhem6PpLbueG53/ozatm1bu2pvXl7eHrf3SLmO//nPf7b53+2h2tbsdXzHHXewcOFCnnrqKe666y4WLlwI2CNEso8//vGP/O53vwPsL359Ph9Tp05ly5YtPP3004D9BXAymWTChAmMHDmS2267DYCuXbsydepUpk6dysMPP8y0adMAuPXWW7npppsoLS1l+PDhXHfddQAsWbKEhQsXcvfdd/PYY4/x6KOPAvDJJ5/whz/8gQkTJvDUU085PU2PPPII119/Pddcc40zCgXgl7/8JaNHj6awsJA+ffo45R+M9h5Jbd3Vud3ZIf1L6Pfddx/Lly/no48+omvXrk7Pw80339xkuzvuuAOAsWPHNomVlpYC8NOf/rTJczZhCQaD3Hrrrbzyyivk5eU57/3Nb36DpmnO6//8z/8E4LbbbuPZZ59l/fr1hMNhpz6TJk1ytu3cuTM///nPnfqvX7+eZcuW8fjjj/Nf//VfAMyYMYP58+cze/ZsAK644goAjjvuOC6//HKKi4upqqqib9++AEyYMIHbb7/d2cc999wD4NRx2LBhKKW44IILePDBB50P0/nz5zc5TvPmzePdd9/l+uuvp66uzon/85//dJIgsLt4AUaNGsWDDz7I0KFD6dKlC8OHD2ft2rW43W7Gjx/P+PHj2bx5MwB+v5+LL76YPn36MG3aNOfDuK6ujgULFhAKhQBwuVy7bOv555+/X9v60UcfNfklz121NWtP29vY2LjP25rdrr20dfr06ViWBeybc/vpp58eMW2F3Z/bO++8s8X23nDDDfu1vSeeeOJet/dIamu2HS21N/u+7GdUtr1+vx/Yf9eypmkttjcQCOzxZ/L++ozKbren5zYej3+vc7u7f7dut7vN53bnz6gJEybs9jp+77332s11rGma82dd3/6d9LPPPsu8efOc6yJ7D9ShQwfOPfdcRo0axcyZM53hXKWlpZx77rm89957DBw4kIKCAsD+1v7RRx/luuuuY9GiRTz44IOA/UWrz+dz7suKioqceoVCISoqKigsLHT237VrV37729+STqdZsWIFkyZNYtmyZViWRSKRQNM0dF13rinTNOnfvz+PPPIIZ5xxBsuXL2/W3uzz/m7vxIkTj5i27urc7sx1yy233NLi3xwCPB4Pffv2ZdiwYfTt2xePxwPgHJysbNdkz549m8RPOeUUwD7ZO+rVq1eT1927d+fMM890Xnfr1o2ysjLn9QknnADYJ7tXr14MGzaMk046yalPNtHZWV5eHsceeyyBQIAhQ4bQoUMHAMrKypxsFuCoo44DRnr9AAAQD0lEQVQCYNCgQZx11ln079+fCy64gHfeeYchQ4Zw+umnNyl39erVDBkyhDPOOMP5ECwrK0MpxdChQ52Lori4GLATjOyHWmlpKSNGjKBLly4888wzDBkyhKuuusrp/QHYsGEDQ4cOpWfPnkycOJGxY8dy6aWXsnr16mb/E33ooYcYMmQIo0eP5ic/+Qmnn346gwcPZuPGjQwdOpTRo0eTn5/vDJv7/PPPGTJkCLFYjE8//ZRLLrmEqVOnsnbtWgYMGADYc2e6du1Kp06dWLNmDQMGDEDXde69915KS0v54Q9/SDKZZPjw4YRCIRYuXEi/fv2c7YcNG8brr7/OkiVLuPTSS/nBD37ASy+9xIABAzj22GPZunUrpaWldOrUifXr1zNs2DA2b97Mt99+y0033cQ111zj7DcYDLJw4UJn+2XLljFgwAB8Ph8bNmzgsssu47zzziMSiTBs2DCWLl3KddddR6dOndi0aRMDBw6ksrKS8vJyxo0bx8qVKxk2bBi9e/emsbGRxx57DL/fz5w5cxg6dCi9e/dG13Un/j//8z/MnTvX6VZ97LHH6NKlC7Nnz2bkyJH07duXF154gZdeeolzzjmHv/3tb4TDYXr37k3Hjh1Jp9P4/X5mz57NhAkT6N27N19++SWJRIIZM2Y411jv3r1RSjWpT35+Pr1798YwDGpraznrrLNYsWIFF154Ib1798bj8fCnP/2JKVOmMHv2bMaNG0fv3r2pr6+nR48eFBcXs3r1asaOHUv37t0xDIOvvvqKr776ihtuuIExY8Zw/PHHs3HjRjZs2MA999zDjTfeyEknnYTP5+Orr76itraWWbNmMW7cOPr06cPLL79MMpmke/fuvPLKK3Tu3Jnu3bvTtWtXhg4dyldffcWsWbOYMGECJ554Ihs3bmTgwIH079+fDz74gLPPPpvu3bvj9Xr56quv2LBhA7NmzeKYY46he/fuuFwu+vXrx9FHH80rr7zC5MmTOe644wgEApSXl3PKKafws5/9jEmTJtG9e3dSqRSjR49m8eLFWJbFeeedR1lZGW63G6UUN9xwA08//TTjxo2jrKwMXdfx+XzccMMNvPvuu8yZM4cTTjjB+dbztttu4+mnn+Y//uM/6NOnD6tWraJLly4sX76cyspKjjnmGMrKyujRowc//elPmTVrFk8//TTnn38+vXr1Ytu2bVx00UW8+uqruN1uzjnnHMrKypwvGLL16d69O2VlZQSDQcaPH89zzz3Hxo0bmTlzpvNjr/369ePFF1/kmWeeYfLkyZSVlbF+/XqGDBnC008/jaZpHHfccXTu3JmqqirmzJnDihUrOPbYYzn11FP59ttvaWhoYM6cOXz44YeMHTuW4cOHU11dTVVVFQsWLGDFihV0796d4cOH88QTT+D3+/nHP/5BdXU10WiUU089FbfbzejRo5k7dy4rVqygd+/eDB8+nHfffZeRI0fy3nvv4fP5nP1WVVU1qU88HufUU09l27ZtDB8+nL///e9s3ryZESNGcOqpp1JeXk46neajjz5ixYoVDBw4kFNPPZUbb7yRsWPHcskllzBx4kSGDh0KwK9+9Sssy6Jnz554vV4GDx4M2N8K6rpOz5496dGjB1OmTCEYDHLnnXdiWRZDhgzB6/UyYMAAwuEww4YNo3Pnzlx//fWUlpY6/895/PHHufTSS53yTzvtNPx+P5dffjkTJ07k5z//OZdddpmz3/nz5zepT/Zauv322znvvPOYNm0aP/7xj7ngggsA+8u5vn37csMNN+D1ejn77LNZtWoVmzdv5uijj+brr7/G4/EwcuRIPvzwQx5++GFqa2uZP38+brebkSNH8umnn/L4449TW1vLU089Rb9+/Rg7diyff/45Dz/8MG63m/nz5+PxeBg7diyLFi3i73//O/369eP9999n7dq1jBw5kkgkQiKRoK6ujvnz5xMKhRg3bhzPPvss0WiUoUOHsmnTJlwuFyNHjmTdunVN6rN+/XpGjhzJmjVrqK6u5gc/+AGvvfYaxxxzDKNGjeKzzz7jvffeY8iQIcyfP58OHTowcuRITNPkjTfe4Ouvv8bv93PVVVdRVFSEz+djzpw5LF68mBdffJErr7ySHj16MHfuXBYvXsy6deu4++676dq1K4WFhcyZM4fnn3+eF198kauvvpouXbrw9ttvc++99/Lvf/+baDTK4MGDKSoq4oQTTmDNmjVO2ddccw2lpaVUVVXx0UcfkUqlyM3N5YorrqCoqIiCgoImdcmWk5uby7vvvss333xDQ0MDt9xyC8XFxc5Q8m3btvHiiy8yb948ioqK6NWrF7/5zW9YtmwZK1euZNasWXTo0IHCwkLOPPNMunXrRrdu3TjmmGMoLS3liy++YOjQoXg8Hs4880z+/ve/c/7551NVVcXJJ5/s3CutXbuWoUOH0rFjR8444wwefvhhNmzY4Fxna9eupUOHDvzoRz8C4NNPP+VHP/oR/fv3Z/Xq1Tz55JN88MEHzJ49m5KSEiKRCP369cPlctGnTx8mTJgAQE5ODs8++yzXX389N954I2PGjOHEE0/km2++4be//S0TJ07kuOOOo6amhr59+zrtXbp0aZvbe8YZZ+xVe9euXUtJSYlzn7VzW5944gk+/PDDw6Kt2b9vqb3NKHHImDhxovO46KKLVI8ePdpdfF+Vfd5556mamho1e/Zs9dprr6np06cf8vHWtj3nnHNUTU2NOuWUU5RhGOryyy8/rOMDBgxQixYtUosXL1annXaaeuKJJ1qNt2Xb9hifNm2auvzyy1VFRYVKpVLqoosuahLftm2bSiaTexyvqKjYo/j06dN3W05b6rOn+73mmmvUNddco7Kuu+66FmOtbXsoxa+88kr17LPPqokTJ6qpU6eqd95557CNX3HFFUoppc4++2yllHI+u/ZXfNq0aQe1nKlTpyrTNNUvfvELVV9fry655JJW423Z9vvEb7755v1SvlJKvfXWW2rp0qXqrbfeUjtavXq1WrZs2T6Jt1T+W2+91eL2ba3PrsppKb6jioqKNsW3bdv2vctp6z73VTyRSLQpHo/H90k5rcUP6TkgR5rW5ra0p/i+Kru1+TqHcrytc5AO13hrc6tairdl2/YYz84XKykpwePxON8+tzaPbHfxkpKSPYqvXbt2t+W0pT57ut+W5sG1NjfuUI+3NrfvcIzvPF8xOz9hf8Wz8yEPVjmtzcNsKd6Wbb9PvLq6er+UP3PmTD755BPC4TCffPIJM2bMcOIff/wxoVDoe8ezw8t2jn/yySctbt/W+uyqnJ3jqVSqyeOXv/xls3gymWw1/qtf/WqPt8+W35Zt21r2rrafO3cuEydO5NZbbwVg1qxZgD0McE/iP/vZz3a5/dy5c7nooov2uPxmWkxLRLv09ddfN3ldXV3d7uL7quznnnuuSfyBBx445OOtbbt69eom8RUrVhzW8ayXX35Z3XTTTWpnLcXbsm17ir/xxhtq5cqVzuvly5cf1nHLstSKFSvUggUL1P/+7/+qWCzWYqy1bfc0/tRTT+2Tcr5P+dkeg50djvFvv/1WvfLKK6q6ulrdfffd6rPPPjus4ytXrlTXXnut2rBhg1JKqQ8++KDVeFu2bY/xHXv3lFLqhhtuOKzjPXv2VFOmTFFTpkxRkydPVr169VJKKXX88cfvk3hL5bdl27aWvavtJ02apJRS6s0331Rz5sxxegQPVnxnkoAIIYQQQhyB7r33XjVlyhQ1Z84cNWXKFHXPPfcc1vGbb765Sft/97vf7ff4wdinUkpNnjzZia1atUp16tTpoMZ3JgmIEEIIIcQRKpVKqfLycpVKpdSiRYsO+/iODkb8QO2zvr6+SXzhwoUHNb6zQ/qHCIUQQgghxN5p7YebJb7v4gMHDmw3dTmY8Z0d0r8DIoQQQggh9k4wGOSRRx5xXk+fPl3i+zieTqfbTV0OZryZFvtFhBBCCCHEYa09LWJzuMbbU10OZnxnMgRLCCGEEEIIccDI74AIIYQQQgghDhhJQIQQQgghhBAHjCQgQgghhBBCiANGEhAhhBB75ZZbbkHTtBYft99++wGvz+LFi9E0jaqqqgO+byGEEHtOluEVQgix1wKBAK+99lqzeNeuXQ9CbYQQQhwKJAERQgix13RdZ9CgQQe7GkIIIQ4hMgRLCCHEfqNpGgsWLGDu3LmUlJSQk5PD5MmTaWhoaLLdt99+y/nnn09+fj7BYJDTTz+dDz/8sFl5Tz75JP3798fv91NcXMxZZ53Fxo0bm5U1evRoQqEQPXr04Mknn9yvbRRCCNE2koAIIYT4XgzDaPbY8Sem7rvvPj7//HOeeOIJFixYwF/+8heuuuoq5+8bGhr48Y9/zAcffMD999/P0qVLSSaTjBgxgi+++MLZbtGiRUyaNIkBAwawfPlyHn30UXr06EFlZWWT+lx66aWMGjWKv/71r/Tr14/Jkyezbt26/X8ghBBC7BEZgiWEEGKvNTY24vF4msVff/11RowYAYDP5+Ovf/0rLpcLAL/fz1VXXcUtt9xCr169ePzxx9m4cSNr1qyhT58+AJxxxhmUlZWxYMECFi9eTF1dHbfccgtXX301f/zjH539nHPOOc32fc011zBjxgwABg0axN/+9jeWL19O796993XzhRBC7AVJQIQQQuy1QCDAqlWrmsV79uzp/Hns2LFO8gEwfvx4rrzySt5//3169erFm2++SZ8+fZzkAyAcDjN27FjefPNNAN555x1isRhXXHHFbus0atQo5885OTl07dqVTZs27VX7hBBC7HuSgAghhNhruq4zcODAXW7ToUOHJq8LCgrweDxs3boVgJqaGjp16tTsfZ06dSISiQBQXV0NwFFHHbXbOuXn5zd57fV6SSQSu32fEEKIA0PmgAghhNivKioqmryuqakhnU7TuXNnAAoLC9m2bVuz95WXl1NYWAhAUVERAFu2bNnPtRVCCLG/SQIihBBiv3r++ecxTdN5vXz5cjRN45RTTgFg2LBhfPbZZ00mijc2NvLCCy/wox/9CIDBgwcTDAZ5/PHHD2zlhRBC7HMyBEsIIcResyyLd999t1m8pKSE7t27A5BMJjn33HOZMWMG//73v5k3bx4TJkzghBNOAGDKlCncc889jBkzhttvv51wOMzChQuJx+PcdNNNAOTl5fHrX/+aefPmYZom5557LpZl8frrrzNx4sTdDgMTQgjRfkgCIoQQYq/F43EGDx7cLD5p0iQWL14MwLXXXktlZSWXXnopqVSK8847j9///vfOtjk5OaxcuZIbb7yR6dOnk06n+eEPf8gbb7xBr169nO2yvyVyzz338MQTT5CTk8PgwYObzTERQgjRvmlqx8XahRBCiH1I0zQWLVrE7NmzD3ZVhBBCtBMyB0QIIYQQQghxwEgCIoQQQgghhDhgZA6IEEKI/UZG+QohhNiZ9IAIIYQQQgghDhhJQIQQQgghhBAHjCQgQgghhBBCiAPm/wPLsvQdBne46wAAAABJRU5ErkJggg=="
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_loss(log; fig_size=(800, 400))\n",
    "    num_epochs = length(log.epoch_train_loss)\n",
    "    p = plot(; title=\"Epoch Loss\", xlabel=\"Epoch\", xlims=(0, num_epochs), xticks=0:num_epochs,\n",
    "               xrotation=90, xtickfontsize=5, ylabel=\"Loss\", framestyle=:semi, size=fig_size)\n",
    "    plot!(p, log.epoch_train_loss; label=\"Train\")\n",
    "    plot!(p, log.epoch_eval_loss; label=\"Eval\")\n",
    "    return p\n",
    "end\n",
    "\n",
    "train_log = (\n",
    "    epoch_train_loss = epoch_train_loss,\n",
    "    epoch_eval_loss  = epoch_eval_loss,\n",
    ")\n",
    "\n",
    "plot_loss(train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss  : 122.6015\n"
     ]
    }
   ],
   "source": [
    "import BSON: bson\n",
    "\n",
    "function load_model(model_file; use_gpu=true)\n",
    "    model = load(model_file)\n",
    "    g = model[:encoder]\n",
    "    f = model[:decoder]\n",
    "    if use_gpu\n",
    "        g = gpu(g)\n",
    "        f = gpu(f)\n",
    "    end\n",
    "    return g, f\n",
    "end\n",
    "\n",
    "seed!(42)\n",
    "g, f = load_model(\"vae_mnist.bson\")\n",
    "eval_loss = mean([-L̄(x) for x in eval_data])\n",
    "println(\"Eval Loss  : \", round(eval_loss; digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAA4AQAAAADLRv+GAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAd2KE6QAAAJZSURBVEjH7ZZNiiQhEIWF2ApxFcGt4NWF3CZ4FcGt4Oh72pUFxTALh+mBdlG2ZsSn8Wsb858N+VaY7zT8hz27/3B/DyMfV/1N/8aUlnrmpjuLsW+A9jbxm02YtE0VWWgbygt2CiP1zaW9Q8Wvr4G7FcsIwMbEnoaoje4kJjZeOcEALXGuRN3Ttt4gUi8HC+n/XNPDxYcwwYb0inFsFxeMrQBjc4chDb8xrlyQqSE+ncQ0c49rSZhmDaOsPn2rvHeAjVLt13ETw2II5iDGNgOnJkMzFG4UcQ9MTILZ4YibkpLtI18OYeR281qSAjynqzLo241hTVj4XSzt0KTnMcN5sYxVGU4eOiGyCnxhbmIKienXYE2s6GXxtoCX+yBmtCK42BmHgFfqs0ANa8Lz/qZB32tgvJEhcqeDGCk6VSQx/bWgNRG9e1Kuy5t57vYMrw7THA7qBzHae5/LlOFOufoj0gsTMy9+wWB7obN0HiWs1EMY6bGPr85HJFwVmtNXEjqIcOWN0tHwtB2ep1PSOYwpEBIdGDebAGO7TGP0A0vDXWxiAR+LoTVL4RBGOmVrSbgqM46NUiuMMh76jY+vChzfKGNFjmLWI6JYJpaBsDVmvvoOFSKdtkkqjD8TZokewoz3lqlmGEbWfdloPCJ49KV2HmhnTohnE9EVhlMYYU9ig+67YBlpHuAylnEFI01r1PP/kt1STmFMWr/2JUqMWwIeHW29vSPEDeiKTT2MEXIcfJuXKGELo2wUygfRsF94qsu+zCHMluUUPnzcGbaGM78ZhzA/40+G+1eYX97r5grx5qwfAAAAAElFTkSuQmCC",
      "text/plain": [
       "28×280 Array{Gray{Bool},2} with eltype Gray{Bool}:\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " ⋮                                     ⋱  \n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(false)  Gray{Bool}(false)     Gray{Bool}(false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAA4AQAAAADLRv+GAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAd2KE6QAAAGOSURBVEjH7ZZBisMwDEUN3hZ8lRzAoKvrBr2KYLYGzeD/3colHRhQYBbVIiay/GJJluJSPvKRC6THlzpOLKpdiPHxHtM8wup8K5KKqbpbYrKNiBFXDHFqKTUTI9Z/wWDH7hYw/C4tpWRiXCVgRFsJcUQ2q7c5HtOyrWS0mIQkzECQbsQsKwuYZhhNghcr7yMT82MwMR2gF0xjTonp8OIA+8X7TMyxMDG2T4zOFSNi9EIMM9dYmtwyphxrqhNjz6l8DEqMW10YLc/kOkZipGjMu6ViRvUTp2TDQFl1mggc7jgaVS0T47PgfzI6gNnKf2wYfElg0hl3HYmYQoyvXi7hyfixa902jNGph+MXYthKXzBIuBHDJpaKqfetGKll2qGTO1KMg9/QdXVheibmUVz6FtPh3MDAoK4TsppxLgZylPi7Z0kc7BeIdNWZE6OLbqmYYgHjmGS81//ZiQH1awRoozILs926hBuPOl4B1lCEGKymMg2jYQX3uGPWLUXPlCUXs4udKbX8VZIwH/mf8g3d8sOKFGTOBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×280 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################# Sample Output ##############################\n",
    "\n",
    "import Distributions: Bernoulli, mode\n",
    "\n",
    "# Sample from the learned model.\n",
    "function model_sample_dist(; use_gpu=true)\n",
    "    μ = zeros(Dz)\n",
    "    logσ = zeros(Dz)\n",
    "    if use_gpu\n",
    "        μ = gpu(μ)\n",
    "        logσ = gpu(logσ)\n",
    "    end\n",
    "    z′ = z(μ, logσ)\n",
    "    x′ = f(z′)\n",
    "    return Bernoulli.(cpu(x′))\n",
    "end\n",
    "\n",
    "img(x) = Gray.(reshape(x, 28, 28))\n",
    "\n",
    "seed!(42)\n",
    "image_samples = [model_sample_dist() for i = 1:10]\n",
    "display(hcat(img.(map(x -> rand.(x), image_samples))...))\n",
    "display(hcat(img.(map(x -> mode.(x), image_samples))...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
