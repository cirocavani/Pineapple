{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Deep Learning\n",
    "\n",
    "https://fluxml.ai/\n",
    "\n",
    "https://github.com/FluxML/model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using CuArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTspec = (\n",
    "    input_size = (28, 28, 1),\n",
    "    num_classes = 10,\n",
    "    train_size = 60000,\n",
    "    test_size = 10000,\n",
    ")\n",
    "batch_size = 256;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: type=Array{Array{ColorTypes.Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}, size=(60000,)\n",
      "y: type=Array{Int64,1}, size=(60000,)\n"
     ]
    }
   ],
   "source": [
    "function load_mnist(split=:train)\n",
    "    mnist = Flux.Data.MNIST\n",
    "    \n",
    "    images = mnist.images(split) # Array with N images of 28x28 8-bits gray\n",
    "    labels = mnist.labels(split) # Array with N labels scalar 0-9\n",
    "    \n",
    "    return images, labels\n",
    "end\n",
    "\n",
    "X, y = load_mnist()\n",
    "\n",
    "println(\"X: type=$(typeof(X)), size=$(size(X))\")\n",
    "println(\"y: type=$(typeof(y)), size=$(size(y))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: type=Array{Tuple{Array{Float32,4},Array{Float32,2}},1}, size=(235,)\n"
     ]
    }
   ],
   "source": [
    "import Flux: onehot\n",
    "import Base.Iterators: partition\n",
    "\n",
    "function make_batch(X, y, batch_size)\n",
    "    num_examples = length(X)\n",
    "    num_batches = ceil(Int, num_examples / batch_size)\n",
    "    \n",
    "    batches = Array{Tuple{Array{Float32,4},Array{Float32,2}},1}(undef, num_batches)\n",
    "    batch_indices = partition(1:num_examples, batch_size)\n",
    "    for (i, indices) in enumerate(batch_indices)\n",
    "        n = length(indices)\n",
    "        X_i = Array{Float32,4}(undef, MNISTspec.input_size..., n)\n",
    "        y_i = Array{Float32,2}(undef, MNISTspec.num_classes, n)\n",
    "        for (j, k) in zip(1:n, indices)\n",
    "            X_i[:, :, :, j] = Float32.(reshape(X[k], MNISTspec.input_size...))\n",
    "            y_i[:, j] = Float32.(onehot(y[k], 0:MNISTspec.num_classes-1))\n",
    "        end\n",
    "        batches[i] = (X_i, y_i)\n",
    "    end\n",
    "    \n",
    "    return batches\n",
    "end\n",
    "\n",
    "train_data = make_batch(X, y, batch_size)\n",
    "\n",
    "println(\"Train Data: type=$(typeof(train_data)), size=$(size(train_data))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: type=Tuple{Array{Float32,4},Array{Float32,2}}\n",
      "(28, 28, 1, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "test_data = make_batch(load_mnist(:test)..., MNISTspec.test_size)[1]\n",
    "\n",
    "println(\"Test Data: type=$(typeof(test_data))\")\n",
    "println(size(test_data[1]))\n",
    "println(size(test_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-like API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Flatten end\n",
    "\n",
    "(::Flatten)(x) = reshape(x, :, size(x)[end])\n",
    "\n",
    "struct Reshape\n",
    "    dims\n",
    "end\n",
    "\n",
    "(layer::Reshape)(x) = reshape(x, layer.dims..., size(x)[end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, NNlib.relu), Dense(500, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "hidden_size = 500\n",
    "\n",
    "model = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, relu),\n",
    "    Dense(hidden_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 10×256 CuArray{Float32,2}:\n",
       " 0.114505   0.0771493  0.102166   …  0.0848796  0.132435   0.0846112\n",
       " 0.0873715  0.122454   0.115082      0.0792973  0.0578625  0.101084 \n",
       " 0.135072   0.12598    0.0456826     0.118104   0.111455   0.123017 \n",
       " 0.083376   0.0428141  0.063969      0.0640264  0.0601236  0.0564281\n",
       " 0.169315   0.140546   0.203719      0.135257   0.16321    0.179357 \n",
       " 0.046649   0.0471217  0.0864572  …  0.0498085  0.0503107  0.0419649\n",
       " 0.0535477  0.0722689  0.0944119     0.0648531  0.0774565  0.0723548\n",
       " 0.102301   0.111181   0.0745297     0.130334   0.118817   0.0964773\n",
       " 0.0693899  0.0956539  0.124982      0.144593   0.0977641  0.0877099\n",
       " 0.138474   0.164832   0.0890001     0.128847   0.130565   0.156996 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 2.3745413f0 (tracked)\n",
      "Accuracy: 0.11328125\n",
      "\n",
      "Test\n",
      "Loss: 2.38708f0 (tracked)\n",
      "Accuracy: 0.1152\n"
     ]
    }
   ],
   "source": [
    "import Flux: logitcrossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss(x, y)\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    y_hat = model(x)\n",
    "    return mean(onecold(y_hat) .== onecold(y))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end\n",
    "\n",
    "println()\n",
    "\n",
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    data = gpu(test_data)\n",
    "    loss_ = loss(data...)\n",
    "    acc_ = accuracy(data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9508\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[2] Test accuracy: 0.9654\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[3] Test accuracy: 0.9698\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[4] Test accuracy: 0.9719\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[5] Test accuracy: 0.9728\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[6] Test accuracy: 0.9747\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[7] Test accuracy: 0.9766\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[8] Test accuracy: 0.9767\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[9] Test accuracy: 0.9772\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[10] Test accuracy: 0.9775\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[11] Test accuracy: 0.9769\n",
      "[12] Test accuracy: 0.9770\n",
      "[13] Test accuracy: 0.9783\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[14] Test accuracy: 0.9795\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[15] Test accuracy: 0.9804\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[16] Test accuracy: 0.9783\n",
      "[17] Test accuracy: 0.9810\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[18] Test accuracy: 0.9803\n",
      "[19] Test accuracy: 0.9811\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[20] Test accuracy: 0.9817\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[21] Test accuracy: 0.9824\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[22] Test accuracy: 0.9817\n",
      "[23] Test accuracy: 0.9821\n",
      "[24] Test accuracy: 0.9825\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[25] Test accuracy: 0.9821\n",
      "[26] Test accuracy: 0.9822\n",
      "[27] Test accuracy: 0.9822\n",
      "[28] Test accuracy: 0.9813\n",
      "[29] Test accuracy: 0.9818\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[30] Test accuracy: 0.9827\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[31] Test accuracy: 0.9827\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[32] Test accuracy: 0.9827\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[33] Test accuracy: 0.9827\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[34] Test accuracy: 0.9828\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[35] Test accuracy: 0.9828\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[36] Test accuracy: 0.9827\n",
      "[37] Test accuracy: 0.9829\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[38] Test accuracy: 0.9827\n",
      "[39] Test accuracy: 0.9826\n",
      "[40] Test accuracy: 0.9827\n",
      "[41] Test accuracy: 0.9826\n",
      "[42] Test accuracy: 0.9826\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[43] Test accuracy: 0.9828\n",
      "[44] Test accuracy: 0.9829\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[45] Test accuracy: 0.9830\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[46] Test accuracy: 0.9830\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[47] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[48] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[49] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[50] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[51] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[52] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[53] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[54] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[55] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[56] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[57] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[58] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[59] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[60] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[61] Test accuracy: 0.9831\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[62] Test accuracy: 0.9830\n",
      "[63] Test accuracy: 0.9830\n",
      "[64] Test accuracy: 0.9830\n",
      "[65] Test accuracy: 0.9830\n",
      "[66] Test accuracy: 0.9829\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[67] Test accuracy: 0.9829\n",
      "[68] Test accuracy: 0.9826\n",
      "[69] Test accuracy: 0.9826\n",
      "[70] Test accuracy: 0.9826\n",
      "[71] Test accuracy: 0.9826\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[72] Test accuracy: 0.9826\n",
      "[73] Test accuracy: 0.9826\n",
      "[74] Test accuracy: 0.9826\n",
      "[75] Test accuracy: 0.9826\n",
      "[76] Test accuracy: 0.9826\n",
      "[77] Test accuracy: 0.9826\n",
      "[78] Test accuracy: 0.9826\n",
      "[79] Test accuracy: 0.9826\n",
      "[80] Test accuracy: 0.9826\n",
      "[81] Test accuracy: 0.9826\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to mlp_mnist.bson\")\n",
    "        bson(\"mlp_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, NNlib.relu), Dense(500, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"mlp_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.07279701f0 (tracked)\n",
      "Accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    loss_ = loss(test_data...)\n",
    "    acc_ = accuracy(test_data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "\n",
    "conv1_kernel_size = (3, 3)\n",
    "conv1_filter_size = input_size[end] => 16\n",
    "conv1_pad = (1, 1)\n",
    "pool1_size = (2, 2)\n",
    "\n",
    "conv2_kernel_size = (3, 3)\n",
    "conv2_filter_size = conv1_filter_size.second => 32\n",
    "conv2_pad = (1, 1)\n",
    "pool2_size = (2, 2)\n",
    "\n",
    "conv3_kernel_size = (3, 3)\n",
    "conv3_filter_size = conv2_filter_size.second => 32\n",
    "conv3_pad = (1, 1)\n",
    "pool3_size = (2, 2)\n",
    "\n",
    "fc1_size = prod(input_size[1:2] .÷ pool1_size .÷ pool2_size .÷ pool3_size) * conv3_filter_size.second\n",
    "\n",
    "model = Chain(\n",
    "    Conv(conv1_kernel_size, conv1_filter_size, pad=conv1_pad, relu),\n",
    "    MaxPool(pool1_size),\n",
    "\n",
    "    Conv(conv2_kernel_size, conv2_filter_size, pad=conv2_pad, relu),\n",
    "    MaxPool(pool2_size),\n",
    "\n",
    "    Conv(conv3_kernel_size, conv3_filter_size, pad=conv3_pad, relu),\n",
    "    MaxPool(pool3_size),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(fc1_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 10×256 CuArray{Float32,2}:\n",
       " 0.0268965   0.0520115   0.0376512   …  0.0256713  0.0193849   0.0507047 \n",
       " 0.0204527   0.02113     0.0304092      0.0413319  0.0450546   0.0258311 \n",
       " 0.0108412   0.00711891  0.0945252      0.0290647  0.0125918   0.0109416 \n",
       " 0.015458    0.0148641   0.00753938     0.0163237  0.0243562   0.0139373 \n",
       " 0.00486294  0.0224071   0.0165965      0.0144639  0.00979678  0.00589586\n",
       " 0.306127    0.386864    0.375069    …  0.618564   0.387693    0.198621  \n",
       " 0.0432158   0.104996    0.115574       0.0365944  0.0212408   0.0485221 \n",
       " 0.166338    0.202689    0.191758       0.0670858  0.124566    0.133041  \n",
       " 0.260729    0.147857    0.106605       0.111268   0.342465    0.379554  \n",
       " 0.145079    0.0400625   0.0242734      0.0396327  0.0128503   0.132951  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 3.163166f0 (tracked)\n",
      "Accuracy: 0.07421875\n"
     ]
    }
   ],
   "source": [
    "import Flux: crossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss_noise(x, y)\n",
    "    x_aug = x .+ 0.1f0 * gpu(randn(eltype(x), size(x)))\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    y_hat = model(x)\n",
    "    return mean(onecold(y_hat) .== onecold(y))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9495\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[2] Test accuracy: 0.9694\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[3] Test accuracy: 0.9769\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[4] Test accuracy: 0.9801\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[5] Test accuracy: 0.9827\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[6] Test accuracy: 0.9838\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[7] Test accuracy: 0.9850\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[8] Test accuracy: 0.9863\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[9] Test accuracy: 0.9864\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[10] Test accuracy: 0.9868\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[11] Test accuracy: 0.9874\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[12] Test accuracy: 0.9871\n",
      "[13] Test accuracy: 0.9870\n",
      "[14] Test accuracy: 0.9870\n",
      "[15] Test accuracy: 0.9870\n",
      "[16] Test accuracy: 0.9859\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[17] Test accuracy: 0.9910\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[18] Test accuracy: 0.9908\n",
      "[19] Test accuracy: 0.9909\n",
      "[20] Test accuracy: 0.9907\n",
      "[21] Test accuracy: 0.9906\n",
      "[22] Test accuracy: 0.9907\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[23] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[24] Test accuracy: 0.9912\n",
      "[25] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[26] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[27] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[28] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[29] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[30] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[31] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[32] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[33] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[34] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[35] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[36] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[37] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[38] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[39] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[40] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[41] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[42] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[43] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[44] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[45] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[46] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[47] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[48] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[49] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[50] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[51] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[52] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[53] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[54] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[55] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[56] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[57] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[58] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[59] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[60] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[61] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[62] Test accuracy: 0.9912\n",
      "[63] Test accuracy: 0.9912\n",
      "[64] Test accuracy: 0.9912\n",
      "[65] Test accuracy: 0.9912\n",
      "[66] Test accuracy: 0.9912\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[67] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[68] Test accuracy: 0.9911\n",
      "[69] Test accuracy: 0.9911\n",
      "[70] Test accuracy: 0.9910\n",
      "[71] Test accuracy: 0.9910\n",
      "[72] Test accuracy: 0.9910\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[73] Test accuracy: 0.9910\n",
      "[74] Test accuracy: 0.9910\n",
      "[75] Test accuracy: 0.9910\n",
      "[76] Test accuracy: 0.9910\n",
      "[77] Test accuracy: 0.9910\n",
      "[78] Test accuracy: 0.9910\n",
      "[79] Test accuracy: 0.9910\n",
      "[80] Test accuracy: 0.9910\n",
      "[81] Test accuracy: 0.9910\n",
      "[82] Test accuracy: 0.9910\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss_noise, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "    \n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to cnn_mnist.bson\")\n",
    "        bson(\"cnn_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, NNlib.relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"cnn_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.02778018f0 (tracked)\n",
      "Accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    loss_ = loss(test_data...)\n",
    "    acc_ = accuracy(test_data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/autoencoder.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, NNlib.leakyrelu), Dense(500, 50, NNlib.leakyrelu)), Chain(Dense(50, 500, NNlib.leakyrelu), Dense(500, 784, NNlib.leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "hidden_size = 500\n",
    "encoded_size = 50\n",
    "\n",
    "encoder = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, encoded_size, leakyrelu),\n",
    ")\n",
    "\n",
    "decoder = Chain(\n",
    "    Dense(encoded_size, hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, prod(input_size), leakyrelu),\n",
    "    Reshape(input_size),\n",
    ")\n",
    "\n",
    "model = Chain(encoder, decoder)\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    : type=CuArray{Float32,4}, size=(28, 28, 1, 256)\n",
      "x_hat: type=TrackedArray{…,CuArray{Float32,4}}, size=(28, 28, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    x1_hat = model(x1)\n",
    "    println(\"x    : type=$(typeof(x1)), size=$(size(x1))\")\n",
    "    println(\"x_hat: type=$(typeof(x1_hat)), size=$(size(x1_hat))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 0.104881465f0 (tracked)\n",
      "Test\n",
      "Loss: 0.1089153f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "function loss(x)\n",
    "    x_hat = model(x)\n",
    "    err = x_hat .- x\n",
    "    N = length(x)\n",
    "    return sum(err .* err) / N\n",
    "end\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    loss_ = loss(x1)\n",
    "    println(\"Loss: \", loss_)\n",
    "end\n",
    "\n",
    "let\n",
    "    println(\"Test\")\n",
    "    data = gpu(test_data[1])\n",
    "    loss_ = loss(data)\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test loss: 0.0121\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[2] Test loss: 0.0096\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[3] Test loss: 0.0087\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[4] Test loss: 0.0082\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[5] Test loss: 0.0078\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[6] Test loss: 0.0072\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[7] Test loss: 0.0068\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[8] Test loss: 0.0066\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[9] Test loss: 0.0063\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[10] Test loss: 0.0061\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[11] Test loss: 0.0060\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[12] Test loss: 0.0058\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[13] Test loss: 0.0058\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[14] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[15] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[16] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[17] Test loss: 0.0055\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[18] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[19] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[20] Test loss: 0.0053\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[21] Test loss: 0.0052\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[22] Test loss: 0.0051\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[23] Test loss: 0.0051\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[24] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[25] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[26] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[27] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[28] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[29] Test loss: 0.0049\n",
      "[30] Test loss: 0.0051\n",
      "[31] Test loss: 0.0050\n",
      "[32] Test loss: 0.0049\n",
      "[33] Test loss: 0.0048\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[34] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[35] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[36] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[37] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[38] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[39] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[40] Test loss: 0.0047\n",
      "[41] Test loss: 0.0046\n",
      "[42] Test loss: 0.0047\n",
      "[43] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[44] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[45] Test loss: 0.0045\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[46] Test loss: 0.0044\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[47] Test loss: 0.0044\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[48] Test loss: 0.0043\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[49] Test loss: 0.0043\n",
      "[50] Test loss: 0.0044\n",
      "[51] Test loss: 0.0045\n",
      "[52] Test loss: 0.0047\n",
      "[53] Test loss: 0.0045\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[54] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[55] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[56] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[57] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[58] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[59] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[60] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[61] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[62] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[63] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[64] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[65] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[66] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[67] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[68] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[69] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[70] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[71] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[72] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[73] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[74] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[75] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[76] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[77] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[78] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[79] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[80] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[81] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[82] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[83] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[84] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[85] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[86] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[87] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[88] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[89] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[90] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[91] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[92] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[93] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[94] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[95] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[96] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[97] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[98] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[99] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[100] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_loss = Inf\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i][1])\n",
    "            train!(loss, params(model), [(data,)], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    loss_ = let data = gpu(test_data[1])\n",
    "        loss(data)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test loss: %.4f\\n\", epoch_idx, loss_)\n",
    "    \n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if loss_ <= best_loss\n",
    "        println(\" -> New best loss! Saving model out to ae_mnist.bson\")\n",
    "        bson(\"ae_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_loss = loss_\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, NNlib.leakyrelu), Dense(500, 50, NNlib.leakyrelu)), Chain(Dense(50, 500, NNlib.leakyrelu), Dense(500, 784, NNlib.leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"ae_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.0036634277f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "    loss_ = loss(test_data[1])\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
