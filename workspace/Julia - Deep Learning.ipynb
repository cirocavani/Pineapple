{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bE5ihHt-QWZu"
   },
   "source": [
    "# Julia Deep Learning\n",
    "\n",
    "https://fluxml.ai/\n",
    "\n",
    "https://github.com/FluxML/model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nCvwjWQQWZw"
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "using CuArrays\n",
    "\n",
    "CuArrays.allowscalar(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1MgwvZHQWZ5"
   },
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bx4CU89bQWZ7"
   },
   "outputs": [],
   "source": [
    "MNISTspec = (\n",
    "    input_size = (28, 28, 1),\n",
    "    num_classes = 10,\n",
    "    train_size = 60000,\n",
    "    test_size = 10000,\n",
    ")\n",
    "batch_size = 256;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "JO5zsiRcQWZ_",
    "outputId": "d5db211a-c60d-4543-9501-7b7c55f6a071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: type=Array{Array{ColorTypes.Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}, size=(60000,)\n",
      "y: type=Array{Int64,1}, size=(60000,)\n"
     ]
    }
   ],
   "source": [
    "function load_mnist(split=:train)\n",
    "    mnist = Flux.Data.MNIST\n",
    "    \n",
    "    images = mnist.images(split) # Array with N images of 28x28 8-bits gray\n",
    "    labels = mnist.labels(split) # Array with N labels scalar 0-9\n",
    "    \n",
    "    return images, labels\n",
    "end\n",
    "\n",
    "X, y = load_mnist()\n",
    "\n",
    "println(\"X: type=$(typeof(X)), size=$(size(X))\")\n",
    "println(\"y: type=$(typeof(y)), size=$(size(y))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CwgpFe9MQWaJ",
    "outputId": "50a3b89b-889b-43ee-800c-c6edc0362942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: type=Array{Tuple{Array{Float32,4},Array{Float32,2}},1}, size=(235,)\n"
     ]
    }
   ],
   "source": [
    "import Flux: onehot\n",
    "import Base.Iterators: partition\n",
    "\n",
    "function make_batch(X, y, batch_size)\n",
    "    num_examples = length(X)\n",
    "    num_batches = ceil(Int, num_examples / batch_size)\n",
    "    \n",
    "    batches = Array{Tuple{Array{Float32,4},Array{Float32,2}},1}(undef, num_batches)\n",
    "    batch_indices = partition(1:num_examples, batch_size)\n",
    "    for (i, indices) in enumerate(batch_indices)\n",
    "        n = length(indices)\n",
    "        X_i = Array{Float32,4}(undef, MNISTspec.input_size..., n)\n",
    "        y_i = Array{Float32,2}(undef, MNISTspec.num_classes, n)\n",
    "        for (j, k) in zip(1:n, indices)\n",
    "            X_i[:, :, :, j] = Float32.(reshape(X[k], MNISTspec.input_size...))\n",
    "            y_i[:, j] = Float32.(onehot(y[k], 0:MNISTspec.num_classes-1))\n",
    "        end\n",
    "        batches[i] = (X_i, y_i)\n",
    "    end\n",
    "    \n",
    "    return batches\n",
    "end\n",
    "\n",
    "train_data = make_batch(X, y, batch_size)\n",
    "\n",
    "println(\"Train Data: type=$(typeof(train_data)), size=$(size(train_data))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N3kk2nsdQWaO",
    "outputId": "031c1e47-d991-4282-86a5-929c25008d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "syWJzb_0QWaY",
    "outputId": "3538a68c-001b-4a02-ae9f-848f25b40802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 96)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oL1cu3guQWad",
    "outputId": "e9e881bf-dffd-4e01-ede3-12215184b6c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GqP4LE1QQWah",
    "outputId": "1c85bc75-2b38-4716-c163-b424e4731033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ud8nybjcQWao",
    "outputId": "a6b6b195-ee83-4a9c-c560-6fddcc427b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: type=Tuple{Array{Float32,4},Array{Float32,2}}\n",
      "(28, 28, 1, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "test_data = make_batch(load_mnist(:test)..., MNISTspec.test_size)[1]\n",
    "\n",
    "println(\"Test Data: type=$(typeof(test_data))\")\n",
    "println(size(test_data[1]))\n",
    "println(size(test_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgdX8nBkQWax"
   },
   "source": [
    "## Keras-like API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20-jOvryQWa0"
   },
   "outputs": [],
   "source": [
    "struct Flatten end\n",
    "\n",
    "(::Flatten)(x) = reshape(x, :, size(x)[end])\n",
    "\n",
    "struct Reshape\n",
    "    dims\n",
    "end\n",
    "\n",
    "(layer::Reshape)(x) = reshape(x, layer.dims..., size(x)[end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiAOc9XbQWa7"
   },
   "source": [
    "## MLP\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pWfHp-5DQWa9",
    "outputId": "99254191-48cb-464e-aea3-5d894d833159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, relu), Dense(500, 10), softmax)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "hidden_size = 500\n",
    "\n",
    "model = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, relu),\n",
    "    Dense(hidden_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vTcJcNO8QWbB",
    "outputId": "b0307fbc-2fc3-4944-9e4d-0b376ad506de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 CuArray{Float32,2,Nothing}:\n",
       " 0.093467   0.129367   0.109898   …  0.0840953  0.0825193  0.08807  \n",
       " 0.0870419  0.0858421  0.073987      0.0750366  0.166232   0.0609079\n",
       " 0.0742691  0.0793655  0.102899      0.0530104  0.0719442  0.0770067\n",
       " 0.0900969  0.113408   0.145694      0.0946832  0.115897   0.0683134\n",
       " 0.146805   0.135063   0.0947556     0.196797   0.0762894  0.194225 \n",
       " 0.0595226  0.0751179  0.110293   …  0.0928439  0.0936156  0.0587865\n",
       " 0.0691995  0.0749764  0.0734426     0.053724   0.0561824  0.0380275\n",
       " 0.174795   0.156614   0.105358      0.190739   0.13772    0.2101   \n",
       " 0.105024   0.0980081  0.0809184     0.0994558  0.100085   0.0939066\n",
       " 0.0997791  0.0522368  0.102756      0.0596143  0.099516   0.110657 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "hXHbkPqjQWbF",
    "outputId": "fdaf6449-5419-4872-a295-e711d3bed7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 2.3362398\n",
      "Accuracy: 0.1015625\n",
      "\n",
      "Test\n",
      "Loss: 2.3304803\n",
      "Accuracy: 0.1184\n"
     ]
    }
   ],
   "source": [
    "import Flux: logitcrossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss(x, y)\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    ŷ = model(x)\n",
    "    return mean(onecold(cpu(ŷ)) .== onecold(cpu(y)))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end\n",
    "\n",
    "println()\n",
    "\n",
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    data = gpu(test_data)\n",
    "    loss_ = loss(data...)\n",
    "    acc_ = accuracy(data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3sITeQsMQWbK",
    "outputId": "0ffb1904-3d80-4cc0-ef53-f85453478c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9496\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[2] Test accuracy: 0.9640\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[3] Test accuracy: 0.9700\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[4] Test accuracy: 0.9729\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[5] Test accuracy: 0.9749\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[6] Test accuracy: 0.9746\n",
      "[7] Test accuracy: 0.9757\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[8] Test accuracy: 0.9764\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[9] Test accuracy: 0.9765\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[10] Test accuracy: 0.9767\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[11] Test accuracy: 0.9769\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[12] Test accuracy: 0.9776\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[13] Test accuracy: 0.9788\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[14] Test accuracy: 0.9797\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[15] Test accuracy: 0.9794\n",
      "[16] Test accuracy: 0.9780\n",
      "[17] Test accuracy: 0.9802\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[18] Test accuracy: 0.9804\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[19] Test accuracy: 0.9809\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[20] Test accuracy: 0.9814\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[21] Test accuracy: 0.9807\n",
      "[22] Test accuracy: 0.9816\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[23] Test accuracy: 0.9828\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[24] Test accuracy: 0.9818\n",
      "[25] Test accuracy: 0.9814\n",
      "[26] Test accuracy: 0.9812\n",
      "[27] Test accuracy: 0.9815\n",
      "[28] Test accuracy: 0.9806\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[29] Test accuracy: 0.9832\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[30] Test accuracy: 0.9834\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[31] Test accuracy: 0.9834\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[32] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[33] Test accuracy: 0.9835\n",
      "[34] Test accuracy: 0.9835\n",
      "[35] Test accuracy: 0.9835\n",
      "[36] Test accuracy: 0.9835\n",
      "[37] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[38] Test accuracy: 0.9835\n",
      "[39] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[40] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[41] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[42] Test accuracy: 0.9836\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[43] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[44] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[45] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[46] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[47] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[48] Test accuracy: 0.9836\n",
      "[49] Test accuracy: 0.9836\n",
      "[50] Test accuracy: 0.9836\n",
      "[51] Test accuracy: 0.9836\n",
      "[52] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[53] Test accuracy: 0.9836\n",
      "[54] Test accuracy: 0.9836\n",
      "[55] Test accuracy: 0.9836\n",
      "[56] Test accuracy: 0.9836\n",
      "[57] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[58] Test accuracy: 0.9836\n",
      "[59] Test accuracy: 0.9836\n",
      "[60] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[61] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[62] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[63] Test accuracy: 0.9838\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[64] Test accuracy: 0.9837\n",
      "[65] Test accuracy: 0.9836\n",
      "[66] Test accuracy: 0.9835\n",
      "[67] Test accuracy: 0.9837\n",
      "[68] Test accuracy: 0.9835\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[69] Test accuracy: 0.9832\n",
      "[70] Test accuracy: 0.9831\n",
      "[71] Test accuracy: 0.9831\n",
      "[72] Test accuracy: 0.9831\n",
      "[73] Test accuracy: 0.9831\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[74] Test accuracy: 0.9833\n",
      "[75] Test accuracy: 0.9833\n",
      "[76] Test accuracy: 0.9834\n",
      "[77] Test accuracy: 0.9834\n",
      "[78] Test accuracy: 0.9834\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[79] Test accuracy: 0.9834\n",
      "[80] Test accuracy: 0.9834\n",
      "[81] Test accuracy: 0.9834\n",
      "[82] Test accuracy: 0.9834\n",
      "[83] Test accuracy: 0.9834\n",
      "[84] Test accuracy: 0.9834\n",
      "[85] Test accuracy: 0.9834\n",
      "[86] Test accuracy: 0.9834\n",
      "[87] Test accuracy: 0.9834\n",
      "[88] Test accuracy: 0.9834\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to mlp_mnist.bson\")\n",
    "        bson(\"mlp_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XGr8VKKQWbR"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pWjJXxdKQWbU",
    "outputId": "b56d6126-3878-458d-adca-7f93d79a1cfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, relu), Dense(500, 10), softmax)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"mlp_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "H8S30VYpQWbc",
    "outputId": "e3f7c1cb-0464-490a-f688-61603a747d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.07892211\n",
      "Accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    loss_ = loss(test_data...)\n",
    "    acc_ = accuracy(test_data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMXKyAebQWbm"
   },
   "source": [
    "## CNN\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NodbMIjjQWbq",
    "outputId": "bb56c4ac-61d8-4aee-cd44-0d0442dc9fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "\n",
    "conv1_kernel_size = (3, 3)\n",
    "conv1_filter_size = input_size[end] => 16\n",
    "conv1_pad = (1, 1)\n",
    "pool1_size = (2, 2)\n",
    "\n",
    "conv2_kernel_size = (3, 3)\n",
    "conv2_filter_size = conv1_filter_size.second => 32\n",
    "conv2_pad = (1, 1)\n",
    "pool2_size = (2, 2)\n",
    "\n",
    "conv3_kernel_size = (3, 3)\n",
    "conv3_filter_size = conv2_filter_size.second => 32\n",
    "conv3_pad = (1, 1)\n",
    "pool3_size = (2, 2)\n",
    "\n",
    "fc1_size = prod(input_size[1:2] .÷ pool1_size .÷ pool2_size .÷ pool3_size) * conv3_filter_size.second\n",
    "\n",
    "model = Chain(\n",
    "    Conv(conv1_kernel_size, conv1_filter_size, pad=conv1_pad, relu),\n",
    "    MaxPool(pool1_size),\n",
    "\n",
    "    Conv(conv2_kernel_size, conv2_filter_size, pad=conv2_pad, relu),\n",
    "    MaxPool(pool2_size),\n",
    "\n",
    "    Conv(conv3_kernel_size, conv3_filter_size, pad=conv3_pad, relu),\n",
    "    MaxPool(pool3_size),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(fc1_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TV2YmXl5QWb3",
    "outputId": "7169bc75-481f-4d0e-b198-2a89282c0868"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 CuArray{Float32,2,Nothing}:\n",
       " 0.113813   0.120842   0.114023   …  0.120016   0.111879   0.122499 \n",
       " 0.0843035  0.0855561  0.0909145     0.0869676  0.0846347  0.0869116\n",
       " 0.0987269  0.0973447  0.0875537     0.0978547  0.0981303  0.0905437\n",
       " 0.0812439  0.0836764  0.0922618     0.0849064  0.0840095  0.0806501\n",
       " 0.0957331  0.0863312  0.0926881     0.0853744  0.0964106  0.0890015\n",
       " 0.116707   0.117006   0.108214   …  0.124676   0.112974   0.121648 \n",
       " 0.0911451  0.0966948  0.0983504     0.0917298  0.0967833  0.0933034\n",
       " 0.11153    0.111864   0.116489      0.121178   0.111923   0.11844  \n",
       " 0.102121   0.0882416  0.0952028     0.0840419  0.0997559  0.0929312\n",
       " 0.104677   0.112443   0.104302      0.103255   0.1035     0.104072 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wOTH9r0pQWcB",
    "outputId": "f9b5c0c4-bf97-41e7-d575-ef4c7e79ad85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 2.318602\n",
      "Accuracy: 0.09375\n"
     ]
    }
   ],
   "source": [
    "import Flux: crossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss_noise(x, y)\n",
    "    x_aug = x .+ 0.1f0 * gpu(randn(eltype(x), size(x)))\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    ŷ = model(x)\n",
    "    return mean(onecold(cpu(ŷ)) .== onecold(cpu(y)))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-gJemaoGQWcI",
    "outputId": "c80427c6-3a17-436a-b2bd-f8e7ba2a86c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9508\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[2] Test accuracy: 0.9747\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[3] Test accuracy: 0.9787\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[4] Test accuracy: 0.9813\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[5] Test accuracy: 0.9838\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[6] Test accuracy: 0.9844\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[7] Test accuracy: 0.9837\n",
      "[8] Test accuracy: 0.9848\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[9] Test accuracy: 0.9862\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[10] Test accuracy: 0.9868\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[11] Test accuracy: 0.9876\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[12] Test accuracy: 0.9884\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[13] Test accuracy: 0.9883\n",
      "[14] Test accuracy: 0.9884\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[15] Test accuracy: 0.9881\n",
      "[16] Test accuracy: 0.9887\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[17] Test accuracy: 0.9879\n",
      "[18] Test accuracy: 0.9888\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[19] Test accuracy: 0.9886\n",
      "[20] Test accuracy: 0.9888\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[21] Test accuracy: 0.9879\n",
      "[22] Test accuracy: 0.9882\n",
      "[23] Test accuracy: 0.9881\n",
      "[24] Test accuracy: 0.9881\n",
      "[25] Test accuracy: 0.9889\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[26] Test accuracy: 0.9876\n",
      "[27] Test accuracy: 0.9877\n",
      "[28] Test accuracy: 0.9872\n",
      "[29] Test accuracy: 0.9878\n",
      "[30] Test accuracy: 0.9879\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[31] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[32] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[33] Test accuracy: 0.9913\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[34] Test accuracy: 0.9914\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[35] Test accuracy: 0.9913\n",
      "[36] Test accuracy: 0.9911\n",
      "[37] Test accuracy: 0.9911\n",
      "[38] Test accuracy: 0.9911\n",
      "[39] Test accuracy: 0.9912\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[40] Test accuracy: 0.9910\n",
      "[41] Test accuracy: 0.9911\n",
      "[42] Test accuracy: 0.9911\n",
      "[43] Test accuracy: 0.9911\n",
      "[44] Test accuracy: 0.9910\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[45] Test accuracy: 0.9910\n",
      "[46] Test accuracy: 0.9910\n",
      "[47] Test accuracy: 0.9910\n",
      "[48] Test accuracy: 0.9910\n",
      "[49] Test accuracy: 0.9911\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[50] Test accuracy: 0.9911\n",
      "[51] Test accuracy: 0.9911\n",
      "[52] Test accuracy: 0.9911\n",
      "[53] Test accuracy: 0.9911\n",
      "[54] Test accuracy: 0.9911\n",
      "[55] Test accuracy: 0.9911\n",
      "[56] Test accuracy: 0.9911\n",
      "[57] Test accuracy: 0.9911\n",
      "[58] Test accuracy: 0.9911\n",
      "[59] Test accuracy: 0.9911\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss_noise, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "    \n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to cnn_mnist.bson\")\n",
    "        bson(\"cnn_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN6zs-UgQWcR"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0b6tYj7tQWcX",
    "outputId": "792247ca-81fb-42c4-c848-c969a094e2aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"cnn_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ppg74mVPQWcc",
    "outputId": "e78b830d-23d8-4d0b-e894-ae7c21bc66ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.035116393\n",
      "Accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "\n",
    "    loss_ = loss(test_data...)\n",
    "    acc_ = accuracy(test_data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At4QL3tpQWcg"
   },
   "source": [
    "## Autoencoder\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/autoencoder.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "2FF9RV-7QWch",
    "outputId": "1838d9ee-acab-4765-8a74-0d2472425170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, leakyrelu), Dense(500, 50, leakyrelu)), Chain(Dense(50, 500, leakyrelu), Dense(500, 784, leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "hidden_size = 500\n",
    "encoded_size = 50\n",
    "\n",
    "encoder = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, encoded_size, leakyrelu),\n",
    ")\n",
    "\n",
    "decoder = Chain(\n",
    "    Dense(encoded_size, hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, prod(input_size), leakyrelu),\n",
    "    Reshape(input_size),\n",
    ")\n",
    "\n",
    "model = Chain(encoder, decoder)\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0LXdAOnnQWcl",
    "outputId": "0cf93c9d-29c9-479d-ba13-c591a752374a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : type=CuArray{Float32,4,Nothing}, size=(28, 28, 1, 256)\n",
      "x̂ : type=CuArray{Float32,4,CuArray{Float32,2,Nothing}}, size=(28, 28, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    x̂1 = model(x1)\n",
    "    println(\"x : type=$(typeof(x1)), size=$(size(x1))\")\n",
    "    println(\"x̂ : type=$(typeof(x̂1)), size=$(size(x̂1))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nDZoT_N8QWcr",
    "outputId": "a008d303-46f3-41b4-9115-81ab5410549d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Loss: 0.10478948\n",
      "Test\n",
      "Loss: 0.10879664\n"
     ]
    }
   ],
   "source": [
    "function loss(x)\n",
    "    x̂ = model(x)\n",
    "    err = x̂ .- x\n",
    "    N = length(x)\n",
    "    return sum(err .* err) / N\n",
    "end\n",
    "\n",
    "let\n",
    "    println(\"Train\")\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    loss_ = loss(x1)\n",
    "    println(\"Loss: \", loss_)\n",
    "end\n",
    "\n",
    "let\n",
    "    println(\"Test\")\n",
    "    data = gpu(test_data[1])\n",
    "    loss_ = loss(data)\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1H5viCd1QWc1",
    "outputId": "fc28e18f-d387-4bc6-f446-dc2a2d5b41a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test loss: 0.0119\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[2] Test loss: 0.0094\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[3] Test loss: 0.0086\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[4] Test loss: 0.0079\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[5] Test loss: 0.0074\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[6] Test loss: 0.0070\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[7] Test loss: 0.0068\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[8] Test loss: 0.0065\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[9] Test loss: 0.0062\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[10] Test loss: 0.0061\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[11] Test loss: 0.0059\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[12] Test loss: 0.0058\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[13] Test loss: 0.0057\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[14] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[15] Test loss: 0.0055\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[16] Test loss: 0.0055\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[17] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[18] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[19] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[20] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[21] Test loss: 0.0053\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[22] Test loss: 0.0053\n",
      "[23] Test loss: 0.0052\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[24] Test loss: 0.0051\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[25] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[26] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[27] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[28] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[29] Test loss: 0.0049\n",
      "[30] Test loss: 0.0048\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[31] Test loss: 0.0049\n",
      "[32] Test loss: 0.0049\n",
      "[33] Test loss: 0.0049\n",
      "[34] Test loss: 0.0049\n",
      "[35] Test loss: 0.0048\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[36] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[37] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[38] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[39] Test loss: 0.0047\n",
      "[40] Test loss: 0.0047\n",
      "[41] Test loss: 0.0047\n",
      "[42] Test loss: 0.0048\n",
      "[43] Test loss: 0.0047\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[44] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[45] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[46] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[47] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[48] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[49] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[50] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[51] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[52] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[53] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[54] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[55] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[56] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[57] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[58] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[59] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[60] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[61] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[62] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[63] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[64] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[65] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[66] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[67] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[68] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[69] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[70] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[71] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[72] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[73] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[74] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[75] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[76] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[77] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[78] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[79] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[80] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[81] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[82] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[83] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[84] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[85] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[86] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[87] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[88] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[89] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[90] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[91] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[92] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[93] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[94] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[95] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[96] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[97] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[98] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[99] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[100] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_loss = Inf\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i][1])\n",
    "            train!(loss, params(model), [(data,)], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    loss_ = let data = gpu(test_data[1])\n",
    "        loss(data)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test loss: %.4f\\n\", epoch_idx, loss_)\n",
    "    \n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if loss_ <= best_loss\n",
    "        println(\" -> New best loss! Saving model out to ae_mnist.bson\")\n",
    "        bson(\"ae_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_loss = loss_\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0mazJHpQWc5"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ONAmCGZNQWc7",
    "outputId": "89d9ed41-2bb2-4fe1-a4eb-59619e9d5e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, leakyrelu), Dense(500, 50, leakyrelu)), Chain(Dense(50, 500, leakyrelu), Dense(500, 784, leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"ae_mnist.bson\")[:model]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VEWOxFFkQWdB",
    "outputId": "2a526d60-61e6-4222-c7f1-5a7d7b6ace84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Loss: 0.0036881757\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\")\n",
    "    loss_ = loss(test_data[1])\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Julia - Deep Learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
