{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bE5ihHt-QWZu"
   },
   "source": [
    "# Julia Deep Learning\n",
    "\n",
    "https://fluxml.ai/\n",
    "\n",
    "https://github.com/FluxML/model-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nCvwjWQQWZw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "using CuArrays\n",
    "using Plots\n",
    "using Plots.PlotMeasures\n",
    "\n",
    "CuArrays.allowscalar(false)\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1MgwvZHQWZ5"
   },
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bx4CU89bQWZ7"
   },
   "outputs": [],
   "source": [
    "MNISTspec = (\n",
    "    input_size = (28, 28, 1),\n",
    "    num_classes = 10,\n",
    "    train_size = 60000,\n",
    "    test_size = 10000,\n",
    ")\n",
    "batch_size = 256;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "JO5zsiRcQWZ_",
    "outputId": "d5db211a-c60d-4543-9501-7b7c55f6a071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "\n",
      "X:\n",
      "\n",
      "type = Array{Array{Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}\n",
      "size = (60000,)\n",
      "shape = (28, 28)\n",
      "\n",
      "y:\n",
      "\n",
      "type = Array{Int64,1}\n",
      "size = (60000,)\n",
      "\n",
      "\n",
      "Test data\n",
      "\n",
      "X:\n",
      "\n",
      "type = Array{Array{Gray{FixedPointNumbers.Normed{UInt8,8}},2},1}\n",
      "size = (10000,)\n",
      "shape = (28, 28)\n",
      "\n",
      "y:\n",
      "\n",
      "type = Array{Int64,1}\n",
      "size = (10000,)\n"
     ]
    }
   ],
   "source": [
    "function load_mnist(split=:train)\n",
    "    mnist = Flux.Data.MNIST\n",
    "    \n",
    "    images = mnist.images(split) # Array with N images of 28x28 8-bits gray\n",
    "    labels = mnist.labels(split) # Array with N labels scalar 0-9\n",
    "    \n",
    "    return images, labels\n",
    "end\n",
    "\n",
    "X_train, y_train = load_mnist(:train)\n",
    "X_test, y_test = load_mnist(:test)\n",
    "\n",
    "println(\"Train data\\n\")\n",
    "println(\"X:\\n\",\n",
    "        \"\\ntype = \", typeof(X_train),\n",
    "        \"\\nsize = \", size(X_train),\n",
    "        \"\\nshape = \", size(X_train[1]),\n",
    "        \"\\n\")\n",
    "println(\"y:\\n\",\n",
    "        \"\\ntype = \", typeof(y_train),\n",
    "        \"\\nsize = \", size(y_train),\n",
    "        \"\\n\\n\")\n",
    "\n",
    "println(\"Test data\\n\")\n",
    "println(\"X:\\n\",\n",
    "        \"\\ntype = \", typeof(X_test),\n",
    "        \"\\nsize = \", size(X_test),\n",
    "        \"\\nshape = \", size(X_test[1]),\n",
    "        \"\\n\")\n",
    "println(\"y:\\n\",\n",
    "        \"\\ntype = \", typeof(y_test),\n",
    "        \"\\nsize = \", size(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_digit(x, y) = plot(x, xlabel= y!==nothing ? \"Label $(y)\" : \"\",\n",
    "                        guidefontsize=8, legend=false, margin=0mm, link=:both,\n",
    "                        ticks=nothing, border=:none)\n",
    "function plot_digits(x, y=nothing; size=(800, 100), layout=(1, length(x)))\n",
    "    plots = map(1:prod(layout)) do i\n",
    "        xi = x[i]\n",
    "        yi = y !== nothing ? y[i] : nothing\n",
    "        plot_digit(xi, yi)\n",
    "    end\n",
    "    plot(plots..., layout=layout, size=size, bg_color=\"black\", fg_color=\"white\")\n",
    "end\n",
    "\n",
    "sample_indices = rand(1:length(X_train), 10)\n",
    "X_sample = X_train[sample_indices]\n",
    "y_sample = y_train[sample_indices]\n",
    "plot_digits(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (WHCN format):\n",
      "\n",
      "type = Array{Float32,4}\n",
      "size = (28, 28, 1, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "function compute_num_channels(image)\n",
    "    color_type = eltype(image)\n",
    "    if color_type <: Gray\n",
    "        return 1\n",
    "    elseif color_type <: RGB\n",
    "        return 3\n",
    "    else\n",
    "        error(\"Unknown color type: $(color_type)\")\n",
    "    end\n",
    "end\n",
    "\n",
    "function make_whcn_format(images)\n",
    "    width, height = size(images[1])\n",
    "    num_channels = compute_num_channels(images[1])\n",
    "    images_array = map(images) do image\n",
    "        Float32.(reshape(image, width, height, num_channels, 1))\n",
    "    end\n",
    "    images_tensor = cat(images_array...; dims=4)\n",
    "end\n",
    "\n",
    "X_whcn = make_whcn_format(X_sample)\n",
    "println(\"X (WHCN format):\\n\",\n",
    "        \"\\ntype = \", typeof(X_whcn),\n",
    "        \"\\nsize = \", size(X_whcn),\n",
    "        \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (One Hot format):\n",
      "\n",
      "type = Array{Float32,2}\n",
      "size = (10, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Flux: onehot\n",
    "\n",
    "function make_onehot_format(labels, class_vector)\n",
    "    labels_array = map(labels) do label\n",
    "        Float32.(onehot(label, class_vector))\n",
    "    end\n",
    "    hcat(labels_array...)\n",
    "end\n",
    "\n",
    "y_onehot = make_onehot_format(y_sample, 0:9)\n",
    "println(\"y (One Hot format):\\n\",\n",
    "        \"\\ntype = \", typeof(y_onehot),\n",
    "        \"\\nsize = \", size(y_onehot),\n",
    "        \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CwgpFe9MQWaJ",
    "outputId": "50a3b89b-889b-43ee-800c-c6edc0362942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: type=Array{Tuple{Array{Float32,4},Array{Float32,2}},1}, size=(235,)\n"
     ]
    }
   ],
   "source": [
    "import Flux: onehot\n",
    "import Base.Iterators: partition\n",
    "\n",
    "function make_batch(X, y, batch_size)\n",
    "    num_examples = length(X)\n",
    "    num_batches = ceil(Int, num_examples / batch_size)\n",
    "    batch_indices = partition(1:num_examples, batch_size)\n",
    "    batches = map(batch_indices) do indices\n",
    "        X_batch = make_whcn_format(X[indices])\n",
    "        y_batch = make_onehot_format(y[indices], 0:9)\n",
    "        (X_batch, y_batch)\n",
    "    end\n",
    "    return batches\n",
    "end\n",
    "\n",
    "batch_size = 256\n",
    "train_data = make_batch(X_train, y_train, batch_size)\n",
    "\n",
    "println(\"Train Data: type=$(typeof(train_data)), size=$(size(train_data))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N3kk2nsdQWaO",
    "outputId": "031c1e47-d991-4282-86a5-929c25008d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 256)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "syWJzb_0QWaY",
    "outputId": "3538a68c-001b-4a02-ae9f-848f25b40802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 96)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oL1cu3guQWad",
    "outputId": "e9e881bf-dffd-4e01-ede3-12215184b6c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 256)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GqP4LE1QQWah",
    "outputId": "1c85bc75-2b38-4716-c163-b424e4731033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 96)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_data[end][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ud8nybjcQWao",
    "outputId": "a6b6b195-ee83-4a9c-c560-6fddcc427b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: type=Tuple{Array{Float32,4},Array{Float32,2}}\n",
      "(28, 28, 1, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "test_data = make_batch(load_mnist(:test)..., MNISTspec.test_size)[1]\n",
    "\n",
    "println(\"Test Data: type=$(typeof(test_data))\")\n",
    "println(size(test_data[1]))\n",
    "println(size(test_data[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgdX8nBkQWax"
   },
   "source": [
    "## Keras-like API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20-jOvryQWa0"
   },
   "outputs": [],
   "source": [
    "struct Flatten end\n",
    "\n",
    "(::Flatten)(x) = reshape(x, :, size(x)[end])\n",
    "\n",
    "struct Reshape\n",
    "    dims\n",
    "end\n",
    "\n",
    "(layer::Reshape)(x) = reshape(x, layer.dims..., size(x)[end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiAOc9XbQWa7"
   },
   "source": [
    "## MLP\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/mlp.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pWfHp-5DQWa9",
    "outputId": "99254191-48cb-464e-aea3-5d894d833159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, relu), Dense(500, 10), softmax)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "hidden_size = 500\n",
    "\n",
    "model = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, relu),\n",
    "    Dense(hidden_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vTcJcNO8QWbB",
    "outputId": "b0307fbc-2fc3-4944-9e4d-0b376ad506de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 CuArray{Float32,2,Nothing}:\n",
       " 0.178659   0.133649   0.152569   …  0.173248   0.16839    0.153217\n",
       " 0.0885137  0.0622111  0.0637348     0.0587575  0.0562047  0.0878141\n",
       " 0.14292    0.077084   0.134308      0.0889326  0.112031   0.0821616\n",
       " 0.0909256  0.128032   0.126365      0.124029   0.0648823  0.0900216\n",
       " 0.0826455  0.158021   0.102386      0.117134   0.106272   0.167001\n",
       " 0.108827   0.0820533  0.0725608  …  0.0547967  0.0582826  0.0918432\n",
       " 0.0964257  0.119808   0.100351      0.128332   0.175979   0.0916331\n",
       " 0.118307   0.142695   0.106841      0.121777   0.118184   0.124711\n",
       " 0.0493862  0.0398466  0.0531612     0.0541759  0.0570676  0.0557162\n",
       " 0.0433903  0.0566     0.087723      0.0788175  0.0827072  0.0558819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "hXHbkPqjQWbF",
    "outputId": "fdaf6449-5419-4872-a295-e711d3bed7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (batch 1)\n",
      "\n",
      "Loss: 2.3730845\n",
      "Accuracy: 0.1015625\n",
      "\n",
      "Test\n",
      "\n",
      "Loss: 2.3558664\n",
      "Accuracy: 0.0985\n"
     ]
    }
   ],
   "source": [
    "import Flux: logitcrossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss(x, y)\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    ŷ = model(x)\n",
    "    return mean(onecold(cpu(ŷ)) .== onecold(cpu(y)))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train (batch 1)\\n\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end\n",
    "\n",
    "println()\n",
    "\n",
    "let\n",
    "    println(\"Test\\n\")\n",
    "\n",
    "    data = gpu(test_data)\n",
    "    loss_ = loss(data...)\n",
    "    acc_ = accuracy(data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3sITeQsMQWbK",
    "outputId": "0ffb1904-3d80-4cc0-ef53-f85453478c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9495\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[2] Test accuracy: 0.9643\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[3] Test accuracy: 0.9703\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[4] Test accuracy: 0.9719\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[5] Test accuracy: 0.9728\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[6] Test accuracy: 0.9748\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[7] Test accuracy: 0.9754\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[8] Test accuracy: 0.9767\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[9] Test accuracy: 0.9764\n",
      "[10] Test accuracy: 0.9777\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[11] Test accuracy: 0.9779\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[12] Test accuracy: 0.9778\n",
      "[13] Test accuracy: 0.9784\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[14] Test accuracy: 0.9789\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[15] Test accuracy: 0.9785\n",
      "[16] Test accuracy: 0.9782\n",
      "[17] Test accuracy: 0.9792\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[18] Test accuracy: 0.9806\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[19] Test accuracy: 0.9803\n",
      "[20] Test accuracy: 0.9806\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[21] Test accuracy: 0.9818\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[22] Test accuracy: 0.9815\n",
      "[23] Test accuracy: 0.9818\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[24] Test accuracy: 0.9815\n",
      "[25] Test accuracy: 0.9809\n",
      "[26] Test accuracy: 0.9812\n",
      "[27] Test accuracy: 0.9808\n",
      "[28] Test accuracy: 0.9810\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[29] Test accuracy: 0.9814\n",
      "[30] Test accuracy: 0.9817\n",
      "[31] Test accuracy: 0.9818\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[32] Test accuracy: 0.9820\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[33] Test accuracy: 0.9821\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[34] Test accuracy: 0.9822\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[35] Test accuracy: 0.9822\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[36] Test accuracy: 0.9822\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[37] Test accuracy: 0.9822\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[38] Test accuracy: 0.9823\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[39] Test accuracy: 0.9825\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[40] Test accuracy: 0.9825\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[41] Test accuracy: 0.9825\n",
      " -> New best accuracy! Saving model out to mlp_mnist.bson\n",
      "[42] Test accuracy: 0.9823\n",
      "[43] Test accuracy: 0.9823\n",
      "[44] Test accuracy: 0.9823\n",
      "[45] Test accuracy: 0.9824\n",
      "[46] Test accuracy: 0.9823\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[47] Test accuracy: 0.9818\n",
      "[48] Test accuracy: 0.9818\n",
      "[49] Test accuracy: 0.9818\n",
      "[50] Test accuracy: 0.9818\n",
      "[51] Test accuracy: 0.9819\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[52] Test accuracy: 0.9818\n",
      "[53] Test accuracy: 0.9818\n",
      "[54] Test accuracy: 0.9818\n",
      "[55] Test accuracy: 0.9818\n",
      "[56] Test accuracy: 0.9819\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[57] Test accuracy: 0.9819\n",
      "[58] Test accuracy: 0.9819\n",
      "[59] Test accuracy: 0.9819\n",
      "[60] Test accuracy: 0.9819\n",
      "[61] Test accuracy: 0.9819\n",
      "[62] Test accuracy: 0.9819\n",
      "[63] Test accuracy: 0.9819\n",
      "[64] Test accuracy: 0.9819\n",
      "[65] Test accuracy: 0.9819\n",
      "[66] Test accuracy: 0.9819\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "\n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to mlp_mnist.bson\")\n",
    "        bson(\"mlp_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XGr8VKKQWbR"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pWjJXxdKQWbU",
    "outputId": "b56d6126-3878-458d-adca-7f93d79a1cfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Flatten(), Dense(784, 500, relu), Dense(500, 10), softmax)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"mlp_mnist.bson\")[:model]\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "H8S30VYpQWbc",
    "outputId": "e3f7c1cb-0464-490a-f688-61603a747d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "Loss: 0.07115936\n",
      "Accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\\n\")\n",
    "\n",
    "    data = gpu(test_data)\n",
    "    loss_ = loss(data...)\n",
    "    acc_ = accuracy(data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMXKyAebQWbm"
   },
   "source": [
    "## CNN\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NodbMIjjQWbq",
    "outputId": "bb56c4ac-61d8-4aee-cd44-0d0442dc9fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "output_size = MNISTspec.num_classes\n",
    "\n",
    "conv1_kernel_size = (3, 3)\n",
    "conv1_filter_size = input_size[end] => 16\n",
    "conv1_pad = (1, 1)\n",
    "pool1_size = (2, 2)\n",
    "\n",
    "conv2_kernel_size = (3, 3)\n",
    "conv2_filter_size = conv1_filter_size.second => 32\n",
    "conv2_pad = (1, 1)\n",
    "pool2_size = (2, 2)\n",
    "\n",
    "conv3_kernel_size = (3, 3)\n",
    "conv3_filter_size = conv2_filter_size.second => 32\n",
    "conv3_pad = (1, 1)\n",
    "pool3_size = (2, 2)\n",
    "\n",
    "fc1_size = prod(input_size[1:2] .÷ pool1_size .÷ pool2_size .÷ pool3_size) * conv3_filter_size.second\n",
    "\n",
    "model = Chain(\n",
    "    Conv(conv1_kernel_size, conv1_filter_size, pad=conv1_pad, relu),\n",
    "    MaxPool(pool1_size),\n",
    "\n",
    "    Conv(conv2_kernel_size, conv2_filter_size, pad=conv2_pad, relu),\n",
    "    MaxPool(pool2_size),\n",
    "\n",
    "    Conv(conv3_kernel_size, conv3_filter_size, pad=conv3_pad, relu),\n",
    "    MaxPool(pool3_size),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(fc1_size, output_size),\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TV2YmXl5QWb3",
    "outputId": "7169bc75-481f-4d0e-b198-2a89282c0868"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×256 CuArray{Float32,2,Nothing}:\n",
       " 0.115904   0.118493   0.113906   …  0.124623   0.109827   0.113278\n",
       " 0.132425   0.146244   0.122483      0.146046   0.131634   0.124296\n",
       " 0.133791   0.149875   0.132157      0.142459   0.150433   0.158189\n",
       " 0.0849604  0.0776478  0.0858348     0.0803556  0.0850954  0.0844602\n",
       " 0.100588   0.105827   0.0955029     0.099066   0.110376   0.105902\n",
       " 0.078658   0.0683121  0.0817824  …  0.0698694  0.0766497  0.0738479\n",
       " 0.0884483  0.086134   0.0903206     0.0800639  0.0809841  0.0793109\n",
       " 0.0819794  0.0778961  0.0776319     0.0776626  0.0779353  0.0763676\n",
       " 0.0962854  0.087108   0.112195      0.0912792  0.0920803  0.0926253\n",
       " 0.0869617  0.0824621  0.0881867     0.0885751  0.0849853  0.0917228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    display(model(x1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wOTH9r0pQWcB",
    "outputId": "f9b5c0c4-bf97-41e7-d575-ef4c7e79ad85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (batch 1)\n",
      "\n",
      "Loss: 2.3100429\n",
      "Accuracy: 0.0703125\n"
     ]
    }
   ],
   "source": [
    "import Flux: logitcrossentropy, onecold\n",
    "import Statistics: mean\n",
    "\n",
    "function loss_noise(x, y)\n",
    "    x_aug = x .+ 0.1f0 * gpu(randn(eltype(x), size(x)))\n",
    "    logits = model[1:end-1](x)\n",
    "    return logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "function accuracy(x, y)\n",
    "    ŷ = model(x)\n",
    "    return mean(onecold(cpu(ŷ)) .== onecold(cpu(y)))\n",
    "end\n",
    "\n",
    "\n",
    "let\n",
    "    println(\"Train (batch 1)\\n\")\n",
    "    \n",
    "    data1 = gpu(train_data[1])\n",
    "    loss_ = loss_noise(data1...)\n",
    "    acc_ = accuracy(data1...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-gJemaoGQWcI",
    "outputId": "c80427c6-3a17-436a-b2bd-f8e7ba2a86c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test accuracy: 0.9511\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[2] Test accuracy: 0.9744\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[3] Test accuracy: 0.9800\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[4] Test accuracy: 0.9803\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[5] Test accuracy: 0.9826\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[6] Test accuracy: 0.9837\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[7] Test accuracy: 0.9857\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[8] Test accuracy: 0.9864\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[9] Test accuracy: 0.9872\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[10] Test accuracy: 0.9872\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[11] Test accuracy: 0.9878\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[12] Test accuracy: 0.9880\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[13] Test accuracy: 0.9886\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[14] Test accuracy: 0.9891\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[15] Test accuracy: 0.9896\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[16] Test accuracy: 0.9900\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[17] Test accuracy: 0.9895\n",
      "[18] Test accuracy: 0.9893\n",
      "[19] Test accuracy: 0.9886\n",
      "[20] Test accuracy: 0.9887\n",
      "[21] Test accuracy: 0.9884\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[22] Test accuracy: 0.9909\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[23] Test accuracy: 0.9910\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[24] Test accuracy: 0.9911\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[25] Test accuracy: 0.9907\n",
      "[26] Test accuracy: 0.9909\n",
      "[27] Test accuracy: 0.9908\n",
      "[28] Test accuracy: 0.9908\n",
      "[29] Test accuracy: 0.9909\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0e-5!\n",
      "[30] Test accuracy: 0.9917\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[31] Test accuracy: 0.9918\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[32] Test accuracy: 0.9920\n",
      " -> New best accuracy! Saving model out to cnn_mnist.bson\n",
      "[33] Test accuracy: 0.9919\n",
      "[34] Test accuracy: 0.9919\n",
      "[35] Test accuracy: 0.9919\n",
      "[36] Test accuracy: 0.9919\n",
      "[37] Test accuracy: 0.9919\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-6!\n",
      "[38] Test accuracy: 0.9919\n",
      "[39] Test accuracy: 0.9919\n",
      "[40] Test accuracy: 0.9919\n",
      "[41] Test accuracy: 0.9919\n",
      "[42] Test accuracy: 0.9919\n",
      " -> Haven't improved in a while, dropping learning rate to 1.0000000000000002e-7!\n",
      "[43] Test accuracy: 0.9919\n",
      "[44] Test accuracy: 0.9919\n",
      "[45] Test accuracy: 0.9919\n",
      "[46] Test accuracy: 0.9919\n",
      "[47] Test accuracy: 0.9919\n",
      "[48] Test accuracy: 0.9919\n",
      "[49] Test accuracy: 0.9919\n",
      "[50] Test accuracy: 0.9918\n",
      "[51] Test accuracy: 0.9918\n",
      "[52] Test accuracy: 0.9918\n",
      " -> We're calling this converged.\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i])\n",
    "            train!(loss_noise, params(model), [data], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    acc = let data = gpu(test_data)\n",
    "        accuracy(data...)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test accuracy: %.4f\\n\", epoch_idx, acc)\n",
    "    \n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        println(\" -> Early-exiting: We reached our target accuracy of 99.9%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if acc >= best_acc\n",
    "        println(\" -> New best accuracy! Saving model out to cnn_mnist.bson\")\n",
    "        bson(\"cnn_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN6zs-UgQWcR"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0b6tYj7tQWcX",
    "outputId": "792247ca-81fb-42c4-c848-c969a094e2aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 16=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, relu), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Flatten(), Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"cnn_mnist.bson\")[:model]\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ppg74mVPQWcc",
    "outputId": "e78b830d-23d8-4d0b-e894-ae7c21bc66ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "Loss: 0.02866702\n",
      "Accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\\n\")\n",
    "\n",
    "    data = gpu(test_data)\n",
    "    loss_ = loss_noise(data...)\n",
    "    acc_ = accuracy(data...)\n",
    "\n",
    "    println(\"Loss: \", loss_)\n",
    "    println(\"Accuracy: \", acc_)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At4QL3tpQWcg"
   },
   "source": [
    "## Autoencoder\n",
    "\n",
    "https://github.com/FluxML/model-zoo/blob/master/vision/mnist/autoencoder.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "2FF9RV-7QWch",
    "outputId": "1838d9ee-acab-4765-8a74-0d2472425170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, leakyrelu), Dense(500, 50, leakyrelu)), Chain(Dense(50, 500, leakyrelu), Dense(500, 784, leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = MNISTspec.input_size\n",
    "hidden_size = 500\n",
    "encoded_size = 50\n",
    "\n",
    "encoder = Chain(\n",
    "    Flatten(),\n",
    "    Dense(prod(input_size), hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, encoded_size, leakyrelu),\n",
    ")\n",
    "\n",
    "decoder = Chain(\n",
    "    Dense(encoded_size, hidden_size, leakyrelu),\n",
    "    Dense(hidden_size, prod(input_size), leakyrelu),\n",
    "    Reshape(input_size),\n",
    ")\n",
    "\n",
    "model = Chain(encoder, decoder)\n",
    "\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0LXdAOnnQWcl",
    "outputId": "0cf93c9d-29c9-479d-ba13-c591a752374a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : type=CuArray{Float32,4,Nothing}, size=(28, 28, 1, 256)\n",
      "x̂ : type=CuArray{Float32,4,CuArray{Float32,2,Nothing}}, size=(28, 28, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    x̂1 = model(x1)\n",
    "    println(\"x : type=$(typeof(x1)), size=$(size(x1))\")\n",
    "    println(\"x̂ : type=$(typeof(x̂1)), size=$(size(x̂1))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nDZoT_N8QWcr",
    "outputId": "a008d303-46f3-41b4-9115-81ab5410549d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (batch 1)\n",
      "\n",
      "Loss: 0.10489251\n",
      "\n",
      "Test\n",
      "\n",
      "Loss: 0.108690426\n"
     ]
    }
   ],
   "source": [
    "function loss(x)\n",
    "    x̂ = model(x)\n",
    "    err = x̂ .- x\n",
    "    N = length(x)\n",
    "    return sum(err .* err) / N\n",
    "end\n",
    "\n",
    "let\n",
    "    println(\"Train (batch 1)\\n\")\n",
    "    x1 = gpu(train_data[1][1])\n",
    "    loss_ = loss(x1)\n",
    "    println(\"Loss: \", loss_)\n",
    "end\n",
    "\n",
    "println()\n",
    "\n",
    "let\n",
    "    println(\"Test\\n\")\n",
    "    data = gpu(test_data[1])\n",
    "    loss_ = loss(data)\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1H5viCd1QWc1",
    "outputId": "fc28e18f-d387-4bc6-f446-dc2a2d5b41a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test loss: 0.0119\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[2] Test loss: 0.0094\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[3] Test loss: 0.0085\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[4] Test loss: 0.0078\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[5] Test loss: 0.0073\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[6] Test loss: 0.0068\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[7] Test loss: 0.0066\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[8] Test loss: 0.0063\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[9] Test loss: 0.0061\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[10] Test loss: 0.0059\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[11] Test loss: 0.0058\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[12] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[13] Test loss: 0.0056\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[14] Test loss: 0.0055\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[15] Test loss: 0.0054\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[16] Test loss: 0.0053\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[17] Test loss: 0.0053\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[18] Test loss: 0.0052\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[19] Test loss: 0.0051\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[20] Test loss: 0.0051\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[21] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[22] Test loss: 0.0051\n",
      "[23] Test loss: 0.0051\n",
      "[24] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[25] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[26] Test loss: 0.0050\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[27] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[28] Test loss: 0.0049\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[29] Test loss: 0.0048\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[30] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[31] Test loss: 0.0047\n",
      "[32] Test loss: 0.0047\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[33] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[34] Test loss: 0.0046\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[35] Test loss: 0.0048\n",
      "[36] Test loss: 0.0047\n",
      "[37] Test loss: 0.0047\n",
      "[38] Test loss: 0.0048\n",
      "[39] Test loss: 0.0046\n",
      " -> Haven't improved in a while, dropping learning rate to 0.0001!\n",
      "[40] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[41] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[42] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[43] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[44] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[45] Test loss: 0.0039\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[46] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[47] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[48] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[49] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[50] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[51] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[52] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[53] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[54] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[55] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[56] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[57] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[58] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[59] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[60] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[61] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[62] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[63] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[64] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[65] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[66] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[67] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[68] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[69] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[70] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[71] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[72] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[73] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[74] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[75] Test loss: 0.0038\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[76] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[77] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[78] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[79] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[80] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[81] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[82] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[83] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[84] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[85] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[86] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[87] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[88] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[89] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[90] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[91] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[92] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[93] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[94] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[95] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[96] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[97] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[98] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[99] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n",
      "[100] Test loss: 0.0037\n",
      " -> New best loss! Saving model out to ae_mnist.bson\n"
     ]
    }
   ],
   "source": [
    "import Flux: train!\n",
    "import BSON: bson\n",
    "import Printf: @printf\n",
    "\n",
    "optimizer = ADAM(0.001)\n",
    "\n",
    "best_loss = Inf\n",
    "last_improvement = 0\n",
    "for epoch_idx in 1:100\n",
    "    # Train for a single epoch\n",
    "    for i in 1:length(train_data)\n",
    "        let data = gpu(train_data[i][1])\n",
    "            train!(loss, params(model), [(data,)], optimizer)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Calculate accuracy:\n",
    "    loss_ = let data = gpu(test_data[1])\n",
    "        loss(data)\n",
    "    end\n",
    "    \n",
    "    @printf(\"[%d] Test loss: %.4f\\n\", epoch_idx, loss_)\n",
    "    \n",
    "    # If this is the best accuracy we've seen so far, save the model out\n",
    "    if loss_ <= best_loss\n",
    "        println(\" -> New best loss! Saving model out to ae_mnist.bson\")\n",
    "        bson(\"ae_mnist.bson\", model = cpu(model), epoch = epoch_idx)\n",
    "        best_loss = loss_\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate:\n",
    "    if epoch_idx - last_improvement >= 5 && optimizer.eta > 1e-6\n",
    "        optimizer.eta /= 10.0\n",
    "        println(\" -> Haven't improved in a while, dropping learning rate to $(optimizer.eta)!\")\n",
    "\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        println(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0mazJHpQWc5"
   },
   "outputs": [],
   "source": [
    "model = nothing\n",
    "\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ONAmCGZNQWc7",
    "outputId": "89d9ed41-2bb2-4fe1-a4eb-59619e9d5e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Chain(Flatten(), Dense(784, 500, leakyrelu), Dense(500, 50, leakyrelu)), Chain(Dense(50, 500, leakyrelu), Dense(500, 784, leakyrelu), Reshape((28, 28, 1))))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import BSON: load\n",
    "\n",
    "model = load(\"ae_mnist.bson\")[:model]\n",
    "model = gpu(model)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VEWOxFFkQWdB",
    "outputId": "2a526d60-61e6-4222-c7f1-5a7d7b6ace84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "\n",
      "Loss: 0.00367186\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    println(\"Test\\n\")\n",
    "    data = gpu(test_data[1])\n",
    "    loss_ = loss(data)\n",
    "    println(\"Loss: \", loss_)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Julia - Deep Learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.4.0-rc2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
